{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c04e93e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import optuna\n",
    "from sklearn.cluster import KMeans\n",
    "import contextlib, sys, io, logging\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2bfd270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_36544\\372339225.py:14: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(sql_query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Golden data loaded into DataFrame:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23038 entries, 0 to 23037\n",
      "Data columns (total 22 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   school_name             23038 non-null  object \n",
      " 1   school_type             23038 non-null  object \n",
      " 2   teachers_fte            22550 non-null  float64\n",
      " 3   enrollment              22863 non-null  float64\n",
      " 4   grade_eight_enrollment  21613 non-null  float64\n",
      " 5   math_counts             22507 non-null  float64\n",
      " 6   math_high_pct           22507 non-null  float64\n",
      " 7   math_low_pct            19960 non-null  float64\n",
      " 8   read_counts             22386 non-null  float64\n",
      " 9   read_high_pct           22386 non-null  float64\n",
      " 10  read_low_pct            19907 non-null  float64\n",
      " 11  pct_hhi_150k_200k       23038 non-null  float64\n",
      " 12  pct_hhi_220k_plus       23038 non-null  float64\n",
      " 13  avg_natwalkind          23038 non-null  float64\n",
      " 14  total_10_14             23038 non-null  int64  \n",
      " 15  pct_10_14               23038 non-null  int64  \n",
      " 16  pct_female_10_14        22937 non-null  float64\n",
      " 17  total_pop               23038 non-null  int64  \n",
      " 18  hhi_150k_200k           23038 non-null  int64  \n",
      " 19  hhi_220k_plus           23038 non-null  int64  \n",
      " 20  schools_in_zip          23038 non-null  int64  \n",
      " 21  dup_rank                23038 non-null  int64  \n",
      "dtypes: float64(13), int64(7), object(2)\n",
      "memory usage: 3.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Connect to database and load data\n",
    "db_params = {\n",
    "    \"host\": os.getenv(\"LOCAL_HOST\"),\n",
    "    \"user\": os.getenv(\"LOCAL_USER\"),\n",
    "    \"password\": os.getenv(\"LOCAL_PW\"),\n",
    "    \"port\": os.getenv(\"LOCAL_PORT\"),\n",
    "    \"dbname\": os.getenv(\"LOCAL_DB\")\n",
    "}\n",
    "\n",
    "try:\n",
    "    conn = psycopg2.connect(**db_params)\n",
    "    print(\"Database connection successful\")\n",
    "    sql_query = \"SELECT * FROM dev.golden_table;\"\n",
    "    df = pd.read_sql_query(sql_query, conn)\n",
    "    conn.close()\n",
    "    print(\"Golden data loaded into DataFrame:\")\n",
    "    print(df.info())\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bf8e01",
   "metadata": {},
   "source": [
    "## 1. Data Overview & Preprocessing\n",
    "We will (a) preview the dataframe loaded as `df`, (b) select numeric features for clustering, (c) impute / drop missing values, (d) scale features, and (e) optionally apply dimensionality reduction (PCA) inside Optuna trials.\n",
    "\n",
    "Metrics to compute later:\n",
    "- Silhouette Score (higher better)\n",
    "- Calinski-Harabasz Index (higher better)\n",
    "- Davies-Bouldin Index (lower better)\n",
    "\n",
    "We'll define reusable helper functions so both model families share logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76b6a229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape: (23038, 22)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "school_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "school_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "teachers_fte",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "enrollment",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "grade_eight_enrollment",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "math_counts",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "math_high_pct",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "math_low_pct",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "read_counts",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "read_high_pct",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "read_low_pct",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pct_hhi_150k_200k",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pct_hhi_220k_plus",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_natwalkind",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "total_10_14",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pct_10_14",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pct_female_10_14",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "total_pop",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hhi_150k_200k",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hhi_220k_plus",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "schools_in_zip",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "dup_rank",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "86b9f8fb-d6a7-4bed-becd-9c4db888c72f",
       "rows": [
        [
         "0",
         "1 LT Charles W. Whitcomb School",
         "1",
         "93.0",
         "1077.0",
         "370.0",
         "71.0",
         "9.0",
         "6.0",
         "71.0",
         "5.0",
         "25.0",
         "4.57",
         "5.03",
         "12.317520901322792",
         "2081",
         "0",
         "0.0",
         "41505",
         "1896",
         "2086",
         "2",
         "1"
        ],
        [
         "1",
         "100 Academy of Engineering and Technology MS",
         "1",
         null,
         "147.0",
         "47.0",
         "5.0",
         "49.0",
         "0.0",
         "7.0",
         "49.0",
         "11.0",
         "2.01",
         "0.75",
         "12.120378210516511",
         "3841",
         "0",
         "0.0",
         "47881",
         "961",
         "358",
         "3",
         "1"
        ],
        [
         "2",
         "1R ELEMENTARY",
         "1",
         "12.0",
         "191.0",
         "25.0",
         "9.0",
         "79.0",
         "80.0",
         "9.0",
         "59.0",
         "50.0",
         "2.33",
         "1.34",
         "8.28723404261702",
         "2008",
         "0",
         "0.0",
         "25966",
         "605",
         "349",
         "4",
         "1"
        ],
        [
         "3",
         "21st Century Charter Sch of Gary",
         "1",
         "96.0",
         "1329.0",
         "102.0",
         "98.0",
         "5.0",
         "0.0",
         "96.0",
         "49.0",
         "20.0",
         "0.54",
         "0.15",
         "8.16719576731746",
         "528",
         "0",
         "0.0",
         "6105",
         "33",
         "9",
         "1",
         "1"
        ],
        [
         "4",
         "21st Century Cyber CS",
         "1",
         "72.0",
         "1536.0",
         "202.0",
         "95.0",
         "49.0",
         "20.0",
         "96.0",
         "69.0",
         "65.0",
         "5.35",
         "8.93",
         "8.938297872387235",
         "2838",
         "0",
         "0.0",
         "50510",
         "2702",
         "4511",
         "4",
         "1"
        ]
       ],
       "shape": {
        "columns": 22,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_name</th>\n",
       "      <th>school_type</th>\n",
       "      <th>teachers_fte</th>\n",
       "      <th>enrollment</th>\n",
       "      <th>grade_eight_enrollment</th>\n",
       "      <th>math_counts</th>\n",
       "      <th>math_high_pct</th>\n",
       "      <th>math_low_pct</th>\n",
       "      <th>read_counts</th>\n",
       "      <th>read_high_pct</th>\n",
       "      <th>...</th>\n",
       "      <th>pct_hhi_220k_plus</th>\n",
       "      <th>avg_natwalkind</th>\n",
       "      <th>total_10_14</th>\n",
       "      <th>pct_10_14</th>\n",
       "      <th>pct_female_10_14</th>\n",
       "      <th>total_pop</th>\n",
       "      <th>hhi_150k_200k</th>\n",
       "      <th>hhi_220k_plus</th>\n",
       "      <th>schools_in_zip</th>\n",
       "      <th>dup_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 LT Charles W. Whitcomb School</td>\n",
       "      <td>1</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1077.0</td>\n",
       "      <td>370.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.03</td>\n",
       "      <td>12.317521</td>\n",
       "      <td>2081</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41505</td>\n",
       "      <td>1896</td>\n",
       "      <td>2086</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100 Academy of Engineering and Technology MS</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>12.120378</td>\n",
       "      <td>3841</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47881</td>\n",
       "      <td>961</td>\n",
       "      <td>358</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1R ELEMENTARY</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.34</td>\n",
       "      <td>8.287234</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25966</td>\n",
       "      <td>605</td>\n",
       "      <td>349</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21st Century Charter Sch of Gary</td>\n",
       "      <td>1</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1329.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.15</td>\n",
       "      <td>8.167196</td>\n",
       "      <td>528</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6105</td>\n",
       "      <td>33</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21st Century Cyber CS</td>\n",
       "      <td>1</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.93</td>\n",
       "      <td>8.938298</td>\n",
       "      <td>2838</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50510</td>\n",
       "      <td>2702</td>\n",
       "      <td>4511</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    school_name school_type  teachers_fte  \\\n",
       "0               1 LT Charles W. Whitcomb School           1          93.0   \n",
       "1  100 Academy of Engineering and Technology MS           1           NaN   \n",
       "2                                 1R ELEMENTARY           1          12.0   \n",
       "3              21st Century Charter Sch of Gary           1          96.0   \n",
       "4                         21st Century Cyber CS           1          72.0   \n",
       "\n",
       "   enrollment  grade_eight_enrollment  math_counts  math_high_pct  \\\n",
       "0      1077.0                   370.0         71.0            9.0   \n",
       "1       147.0                    47.0          5.0           49.0   \n",
       "2       191.0                    25.0          9.0           79.0   \n",
       "3      1329.0                   102.0         98.0            5.0   \n",
       "4      1536.0                   202.0         95.0           49.0   \n",
       "\n",
       "   math_low_pct  read_counts  read_high_pct  ...  pct_hhi_220k_plus  \\\n",
       "0           6.0         71.0            5.0  ...               5.03   \n",
       "1           0.0          7.0           49.0  ...               0.75   \n",
       "2          80.0          9.0           59.0  ...               1.34   \n",
       "3           0.0         96.0           49.0  ...               0.15   \n",
       "4          20.0         96.0           69.0  ...               8.93   \n",
       "\n",
       "   avg_natwalkind  total_10_14  pct_10_14  pct_female_10_14  total_pop  \\\n",
       "0       12.317521         2081          0               0.0      41505   \n",
       "1       12.120378         3841          0               0.0      47881   \n",
       "2        8.287234         2008          0               0.0      25966   \n",
       "3        8.167196          528          0               0.0       6105   \n",
       "4        8.938298         2838          0               0.0      50510   \n",
       "\n",
       "   hhi_150k_200k  hhi_220k_plus  schools_in_zip  dup_rank  \n",
       "0           1896           2086               2         1  \n",
       "1            961            358               3         1  \n",
       "2            605            349               4         1  \n",
       "3             33              9               1         1  \n",
       "4           2702           4511               4         1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric subset shape: (23038, 20)\n",
      "Missing value percentage (top 15):\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "291a8f80-4b7e-4508-a678-0e3e4664ca59",
       "rows": [
        [
         "read_low_pct",
         "0.13590589460890704"
        ],
        [
         "math_low_pct",
         "0.13360534768643112"
        ],
        [
         "grade_eight_enrollment",
         "0.061854327632606995"
        ],
        [
         "read_counts",
         "0.028301067801024395"
        ],
        [
         "read_high_pct",
         "0.028301067801024395"
        ],
        [
         "math_counts",
         "0.023048875770466187"
        ],
        [
         "math_high_pct",
         "0.023048875770466187"
        ],
        [
         "teachers_fte",
         "0.021182394305061202"
        ],
        [
         "enrollment",
         "0.00759614549874121"
        ],
        [
         "pct_female_10_14",
         "0.004384061116416356"
        ],
        [
         "schools_in_zip",
         "0.0"
        ],
        [
         "hhi_220k_plus",
         "0.0"
        ],
        [
         "hhi_150k_200k",
         "0.0"
        ],
        [
         "total_pop",
         "0.0"
        ],
        [
         "pct_hhi_220k_plus",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 15
       }
      },
      "text/plain": [
       "read_low_pct              0.135906\n",
       "math_low_pct              0.133605\n",
       "grade_eight_enrollment    0.061854\n",
       "read_counts               0.028301\n",
       "read_high_pct             0.028301\n",
       "math_counts               0.023049\n",
       "math_high_pct             0.023049\n",
       "teachers_fte              0.021182\n",
       "enrollment                0.007596\n",
       "pct_female_10_14          0.004384\n",
       "schools_in_zip            0.000000\n",
       "hhi_220k_plus             0.000000\n",
       "hhi_150k_200k             0.000000\n",
       "total_pop                 0.000000\n",
       "pct_hhi_220k_plus         0.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Basic shape & preview\n",
    "print(f\"DataFrame shape: {df.shape}\")\n",
    "display(df.head())\n",
    "\n",
    "df_numeric = df.select_dtypes(include=['int64','float64']).copy()\n",
    "print(f\"Numeric subset shape: {df_numeric.shape}\")\n",
    "missing_pct = df_numeric.isna().mean().sort_values(ascending=False)\n",
    "print(\"Missing value percentage (top 15):\")\n",
    "display(missing_pct.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cf8ee3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix ready. Shape: (23038, 20)\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values: simple strategy (median). Could be enhanced later.\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "scaled_features = imputer.fit_transform(df_numeric)\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(scaled_features)\n",
    "print(f\"Feature matrix ready. Shape: {X.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95fb2fd",
   "metadata": {},
   "source": [
    "## 2. Optimization Helpers (Optuna)\n",
    "We define metric computation and a utility to optionally apply PCA inside each trial to reduce dimensionality (tuned as a hyperparameter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a508a851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions and metrics ready.\n"
     ]
    }
   ],
   "source": [
    "# Ensure optuna is available (if running in an environment where pip install is allowed)\n",
    "\n",
    "\n",
    "# Cache original data for reuse\n",
    "X_full = X  # already scaled\n",
    "\n",
    "\n",
    "def prepare_features(trial, X_input):\n",
    "    \"\"\"Optionally apply PCA controlled by trial hyperparameters.\"\"\"\n",
    "    use_pca = trial.suggest_categorical('use_pca', [True, False])\n",
    "    if use_pca:\n",
    "        # limit components between 2 and min(50, n_features)\n",
    "        max_comp = min(50, X_input.shape[1])\n",
    "        n_components = trial.suggest_int('pca_components', 2, max_comp)\n",
    "        pca = PCA(n_components=n_components, random_state=42)\n",
    "        X_red = pca.fit_transform(X_input)\n",
    "        return X_red, pca\n",
    "    return X_input, None\n",
    "\n",
    "\n",
    "def compute_cluster_metrics(X_data, labels):\n",
    "    # Guard for metrics requiring >1 cluster and fewer than n_samples clusters\n",
    "    unique_labels = set(labels)\n",
    "    if len(unique_labels) <= 1 or len(unique_labels) >= len(labels):\n",
    "        return {\n",
    "            'silhouette': float('nan'),\n",
    "            'calinski_harabasz': float('nan'),\n",
    "            'davies_bouldin': float('nan')\n",
    "        }\n",
    "    return {\n",
    "        'silhouette': silhouette_score(X_data, labels),\n",
    "        'calinski_harabasz': calinski_harabasz_score(X_data, labels),\n",
    "        'davies_bouldin': davies_bouldin_score(X_data, labels)\n",
    "    }\n",
    "\n",
    "\n",
    "def objective_wrapper(build_model_fn):\n",
    "    def objective(trial):\n",
    "        X_trial, pca_obj = prepare_features(trial, X_full)\n",
    "        model = build_model_fn(trial)\n",
    "        labels = model.fit_predict(X_trial)\n",
    "        metrics = compute_cluster_metrics(X_trial, labels)\n",
    "        # We'll optimize on silhouette (maximize)\n",
    "        trial.set_user_attr('metrics', metrics)\n",
    "        if pca_obj is not None:\n",
    "            trial.set_user_attr('pca_components_actual', getattr(pca_obj, 'n_components_', None))\n",
    "        return metrics['silhouette']\n",
    "    return objective\n",
    "\n",
    "print(\"Helper functions and metrics ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3babe8f7",
   "metadata": {},
   "source": [
    "## 3. KMeans Optimization\n",
    "We search hyperparameters: n_clusters, init method, algorithm, optional PCA usage & components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6edbd27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna logging suppression active: True\n"
     ]
    }
   ],
   "source": [
    "SUPPRESS_TRIAL_OUTPUT = True  # toggle this to see full trial logs\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def silent_stdout(enabled=True):\n",
    "    if not enabled:\n",
    "        yield\n",
    "        return\n",
    "    new_target = io.StringIO()\n",
    "    old_stdout = sys.stdout\n",
    "    try:\n",
    "        sys.stdout = new_target\n",
    "        yield\n",
    "    finally:\n",
    "        sys.stdout = old_stdout\n",
    "\n",
    "# Reduce Optuna logging level (shows only WARNING+)\n",
    "if SUPPRESS_TRIAL_OUTPUT:\n",
    "    optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "else:\n",
    "    optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "\n",
    "print(\"Optuna logging suppression active:\" , SUPPRESS_TRIAL_OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5532530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running KMeans optimization (silence trials= True ) ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'objective_wrapper' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m silent_stdout(SUPPRESS_TRIAL_OUTPUT):\n\u001b[0;32m     15\u001b[0m     study_kmeans \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m, study_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkmeans_clustering\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m     study_kmeans\u001b[38;5;241m.\u001b[39moptimize(\u001b[43mobjective_wrapper\u001b[49m(build_kmeans), n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m, show_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m SUPPRESS_TRIAL_OUTPUT)\n\u001b[0;32m     18\u001b[0m best_k_params \u001b[38;5;241m=\u001b[39m study_kmeans\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39mparams\n\u001b[0;32m     19\u001b[0m best_k_metrics \u001b[38;5;241m=\u001b[39m study_kmeans\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39muser_attrs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetrics\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\n",
      "\u001b[1;31mNameError\u001b[0m: name 'objective_wrapper' is not defined"
     ]
    }
   ],
   "source": [
    "# --- KMeans Hyperparameter Optimization (enhanced) ---\n",
    "import time\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "\n",
    "N_KMEANS_TRIALS = 40  # adjust if you want a faster/slower search\n",
    "REUSE_EXISTING_KMEANS_STUDY = False  # set True to skip re-optimizing if study_kmeans already present\n",
    "KMEANS_STUDY_NAME = 'kmeans_clustering'\n",
    "\n",
    "if REUSE_EXISTING_KMEANS_STUDY and 'study_kmeans' in globals():\n",
    "    print('[KMeans] Reusing existing Optuna study; skipping optimization.')\n",
    "else:\n",
    "    def build_kmeans(trial):\n",
    "        n_clusters = trial.suggest_int('kmeans_n_clusters', 2, 15)\n",
    "        init = trial.suggest_categorical('kmeans_init', ['k-means++', 'random'])\n",
    "        algorithm = trial.suggest_categorical('kmeans_algorithm', ['lloyd', 'elkan'])\n",
    "        # Tune n_init (sklearn >=1.4 supports int or 'auto')\n",
    "        n_init = trial.suggest_categorical('kmeans_n_init', [10, 20, 30, 'auto'])\n",
    "        return KMeans(\n",
    "            n_clusters=n_clusters,\n",
    "            init=init,\n",
    "            algorithm=algorithm,\n",
    "            n_init=n_init,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    print(f\"[KMeans] Running optimization (silence trials={SUPPRESS_TRIAL_OUTPUT}) ...\")\n",
    "    with silent_stdout(SUPPRESS_TRIAL_OUTPUT):\n",
    "        study_kmeans = optuna.create_study(direction='maximize', study_name=KMEANS_STUDY_NAME)\n",
    "\n",
    "        def objective_wrapper_with_runtime(build_model_fn):\n",
    "            base_objective = objective_wrapper(build_model_fn)\n",
    "            def _inner(trial):\n",
    "                start = time.time()\n",
    "                val = base_objective(trial)\n",
    "                trial.set_user_attr('runtime_sec', time.time() - start)\n",
    "                return val\n",
    "            return _inner\n",
    "\n",
    "        study_kmeans.optimize(\n",
    "            objective_wrapper_with_runtime(build_kmeans),\n",
    "            n_trials=N_KMEANS_TRIALS,\n",
    "            show_progress_bar=not SUPPRESS_TRIAL_OUTPUT\n",
    "        )\n",
    "\n",
    "best_k_params = study_kmeans.best_trial.params\n",
    "best_k_metrics = study_kmeans.best_trial.user_attrs.get('metrics', {})\n",
    "print(\"[KMeans] Best Params:\")\n",
    "print(best_k_params)\n",
    "print(\"[KMeans] Best Metrics:\")\n",
    "print(best_k_metrics)\n",
    "print(f\"[KMeans] Best silhouette: {study_kmeans.best_value:.4f}\")\n",
    "\n",
    "# Build results DataFrame (include inertia if available)\n",
    "kmeans_results = []\n",
    "for t in study_kmeans.trials:\n",
    "    row = {**t.params}\n",
    "    metrics = t.user_attrs.get('metrics', {})\n",
    "    row.update(metrics)\n",
    "    row['runtime_sec'] = t.user_attrs.get('runtime_sec')\n",
    "    # inertia: recompute quickly if silhouette is valid and clusters >1\n",
    "    try:\n",
    "        if not np.isnan(metrics.get('silhouette', np.nan)) and 'kmeans_n_clusters' in t.params:\n",
    "            # Refit minimal model (no PCA) ONLY for inertia if clusters moderate\n",
    "            km_tmp = KMeans(\n",
    "                n_clusters=t.params['kmeans_n_clusters'],\n",
    "                init=t.params['kmeans_init'],\n",
    "                algorithm=t.params['kmeans_algorithm'],\n",
    "                n_init=t.params.get('kmeans_n_init','auto'),\n",
    "                random_state=42\n",
    "            ).fit(X_full)\n",
    "            row['inertia'] = km_tmp.inertia_\n",
    "        else:\n",
    "            row['inertia'] = np.nan\n",
    "    except Exception:\n",
    "        row['inertia'] = np.nan\n",
    "    kmeans_results.append(row)\n",
    "\n",
    "kmeans_results_df = pd.DataFrame(kmeans_results)\n",
    "if not kmeans_results_df.empty:\n",
    "    # Rank by silhouette then inertia (lower inertia better)\n",
    "    kmeans_results_df['inertia_rank'] = kmeans_results_df['inertia'].rank(method='min')\n",
    "    display(kmeans_results_df.sort_values(['silhouette','inertia'], ascending=[False, True]).head(10))\n",
    "    print('[KMeans] Summary:')\n",
    "    print(kmeans_results_df[['silhouette','inertia','runtime_sec']].describe().round(3))\n",
    "else:\n",
    "    print('[KMeans] No trials recorded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58316419",
   "metadata": {},
   "source": [
    "## 4. Gaussian Mixture (GMM) Optimization\n",
    "We tune: n_components, covariance_type, reg_covar, and optional PCA usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ebef59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Running GMM optimization (silence trials=\", SUPPRESS_TRIAL_OUTPUT, \") ...\")\n",
    "\n",
    "def build_gmm(trial):\n",
    "    n_components = trial.suggest_int('gmm_n_components', 2, 15)\n",
    "    covariance_type = trial.suggest_categorical('gmm_covariance_type', ['full', 'tied', 'diag', 'spherical'])\n",
    "    reg_covar = trial.suggest_float('gmm_reg_covar', 1e-6, 1e-2, log=True)\n",
    "    return GaussianMixture(\n",
    "        n_components=n_components,\n",
    "        covariance_type=covariance_type,\n",
    "        reg_covar=reg_covar,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "with silent_stdout(SUPPRESS_TRIAL_OUTPUT):\n",
    "    study_gmm = optuna.create_study(direction='maximize', study_name='gmm_clustering')\n",
    "    study_gmm.optimize(objective_wrapper(build_gmm), n_trials=40, show_progress_bar=not SUPPRESS_TRIAL_OUTPUT)\n",
    "\n",
    "best_g_params = study_gmm.best_trial.params\n",
    "best_g_metrics = study_gmm.best_trial.user_attrs.get('metrics', {})\n",
    "print(\"GMM Best Params:\")\n",
    "print(best_g_params)\n",
    "print(\"GMM Best Metrics:\")\n",
    "print(best_g_metrics)\n",
    "print(f\"Best silhouette: {study_gmm.best_value:.4f}\")\n",
    "\n",
    "gmm_results = []\n",
    "for t in study_gmm.trials:\n",
    "    row = {**t.params}\n",
    "    row.update(t.user_attrs.get('metrics', {}))\n",
    "    gmm_results.append(row)\n",
    "import pandas as pd\n",
    "gmm_results_df = pd.DataFrame(gmm_results)\n",
    "if not gmm_results_df.empty:\n",
    "    display(gmm_results_df.sort_values('silhouette', ascending=False).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2d9a75",
   "metadata": {},
   "source": [
    "## 5. Visualization (2D PCA Projections)\n",
    "We project the full standardized feature matrix to 2 principal components (outside of optimization) for consistent side-by-side cluster plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca62644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Refit best models on (possibly PCA-transformed) feature space chosen by best trial\n",
    "best_kmeans_params = study_kmeans.best_trial.params\n",
    "best_gmm_params = study_gmm.best_trial.params\n",
    "\n",
    "# Build best models again without PCA reduction (for consistent plotting base); PCA only for 2D viz\n",
    "kmeans_best = KMeans(\n",
    "    n_clusters=best_kmeans_params['kmeans_n_clusters'],\n",
    "    init=best_kmeans_params['kmeans_init'],\n",
    "    algorithm=best_kmeans_params['kmeans_algorithm'],\n",
    "    n_init='auto',\n",
    "    random_state=42\n",
    ").fit(X_full)\n",
    "\n",
    "gmm_best = GaussianMixture(\n",
    "    n_components=best_gmm_params['gmm_n_components'],\n",
    "    covariance_type=best_gmm_params['gmm_covariance_type'],\n",
    "    reg_covar=best_gmm_params['gmm_reg_covar'],\n",
    "    random_state=42\n",
    ").fit(X_full)\n",
    "\n",
    "labels_kmeans = kmeans_best.predict(X_full)\n",
    "labels_gmm = gmm_best.predict(X_full)\n",
    "\n",
    "# PCA for viz only\n",
    "pca_viz = PCA(n_components=2, random_state=42)\n",
    "X_2d = pca_viz.fit_transform(X_full)\n",
    "plot_df = pd.DataFrame({\n",
    "    'PC1': X_2d[:,0],\n",
    "    'PC2': X_2d[:,1],\n",
    "    'KMeans_Cluster': labels_kmeans.astype(str),\n",
    "    'GMM_Cluster': labels_gmm.astype(str)\n",
    "})\n",
    "\n",
    "fig1 = px.scatter(plot_df, x='PC1', y='PC2', color='KMeans_Cluster', title='KMeans Clusters (PCA 2D)')\n",
    "fig1.show()\n",
    "fig2 = px.scatter(plot_df, x='PC1', y='PC2', color='GMM_Cluster', title='GMM Clusters (PCA 2D)')\n",
    "fig2.show()\n",
    "\n",
    "print(\"Visualization complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7059a661",
   "metadata": {},
   "source": [
    "## 6. Cluster Profiling & Comparison\n",
    "Generate aggregate statistics per cluster for both algorithms and compare metrics side-by-side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21513850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach cluster labels back to original numeric df\n",
    "profile_df = df_numeric.copy()\n",
    "profile_df['kmeans_cluster'] = labels_kmeans\n",
    "profile_df['gmm_cluster'] = labels_gmm\n",
    "\n",
    "kmeans_profile = profile_df.groupby('kmeans_cluster').agg(['mean','median','count'])\n",
    "gmm_profile = profile_df.groupby('gmm_cluster').agg(['mean','median','count'])\n",
    "\n",
    "print(\"KMeans cluster profile (first 10 features):\")\n",
    "display(kmeans_profile.iloc[:, :30])  # limit columns for display\n",
    "print(\"GMM cluster profile (first 10 features):\")\n",
    "display(gmm_profile.iloc[:, :30])\n",
    "\n",
    "# Consolidate top metrics\n",
    "comparison_df = pd.DataFrame({\n",
    "    'model': ['KMeans', 'GMM'],\n",
    "    'best_silhouette': [study_kmeans.best_value, study_gmm.best_value],\n",
    "    'best_params': [study_kmeans.best_trial.params, study_gmm.best_trial.params]\n",
    "})\n",
    "\n",
    "# Fetch corresponding Calinski-Harabasz and Davies-Bouldin from best trials\n",
    "comparison_df['calinski_harabasz'] = [\n",
    "    study_kmeans.best_trial.user_attrs['metrics']['calinski_harabasz'],\n",
    "    study_gmm.best_trial.user_attrs['metrics']['calinski_harabasz']\n",
    "]\n",
    "comparison_df['davies_bouldin'] = [\n",
    "    study_kmeans.best_trial.user_attrs['metrics']['davies_bouldin'],\n",
    "    study_gmm.best_trial.user_attrs['metrics']['davies_bouldin']\n",
    "]\n",
    "\n",
    "print(\"Model comparison metrics:\")\n",
    "display(comparison_df)\n",
    "\n",
    "# Simple relative ranking summary\n",
    "ranking = comparison_df[['model','best_silhouette','calinski_harabasz','davies_bouldin']].copy()\n",
    "ranking['silhouette_rank'] = ranking['best_silhouette'].rank(ascending=False)\n",
    "ranking['ch_rank'] = ranking['calinski_harabasz'].rank(ascending=False)\n",
    "ranking['db_rank'] = ranking['davies_bouldin'].rank(ascending=True)\n",
    "ranking['avg_rank'] = ranking[['silhouette_rank','ch_rank','db_rank']].mean(axis=1)\n",
    "print(\"Ranking summary:\")\n",
    "display(ranking.sort_values('avg_rank'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a19bc08",
   "metadata": {},
   "source": [
    "## 7. Notes & Next Steps\n",
    "Potential enhancements:\n",
    "- Add DBSCAN / HDBSCAN for density-based perspective.\n",
    "- Use feature selection or domain-driven grouping before clustering.\n",
    "- Evaluate stability across bootstrap samples.\n",
    "- Store cluster assignments back to database for downstream analytics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ee0c97",
   "metadata": {},
   "source": [
    "## 8. Persist Best Models\n",
    "Save best KMeans and GMM models, hyperparameters, and metrics into `src/unsupervised/` for reuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3be311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, joblib, pathlib, datetime\n",
    "\n",
    "# Directory to save models\n",
    "save_dir = pathlib.Path('src') / 'unsupervised'\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Recreate best models if not already in memory (guard if cell order differs)\n",
    "if 'kmeans_best' not in globals():\n",
    "    from sklearn.cluster import KMeans\n",
    "    kmeans_best = KMeans(\n",
    "        n_clusters=study_kmeans.best_trial.params['kmeans_n_clusters'],\n",
    "        init=study_kmeans.best_trial.params['kmeans_init'],\n",
    "        algorithm=study_kmeans.best_trial.params['kmeans_algorithm'],\n",
    "        n_init='auto',\n",
    "        random_state=42\n",
    "    ).fit(X_full)\n",
    "\n",
    "# GMM study might not yet be executed; wrap in try\n",
    "try:\n",
    "    if 'study_gmm' in globals():\n",
    "        from sklearn.mixture import GaussianMixture\n",
    "        if 'gmm_best' not in globals():\n",
    "            gmm_best = GaussianMixture(\n",
    "                n_components=study_gmm.best_trial.params['gmm_n_components'],\n",
    "                covariance_type=study_gmm.best_trial.params['gmm_covariance_type'],\n",
    "                reg_covar=study_gmm.best_trial.params['gmm_reg_covar'],\n",
    "                random_state=42\n",
    "            ).fit(X_full)\n",
    "    else:\n",
    "        gmm_best = None\n",
    "except Exception as e:\n",
    "    print(f\"Could not rebuild GMM best model: {e}\")\n",
    "    gmm_best = None\n",
    "\n",
    "# Metadata assembly\n",
    "now_ts = datetime.datetime.utcnow().isoformat() + 'Z'\n",
    "meta = {\n",
    "    'timestamp_utc': now_ts,\n",
    "    'kmeans': {\n",
    "        'params': study_kmeans.best_trial.params,\n",
    "        'metrics': study_kmeans.best_trial.user_attrs.get('metrics', {})\n",
    "    },\n",
    "}\n",
    "if 'study_gmm' in globals():\n",
    "    meta['gmm'] = {\n",
    "        'params': study_gmm.best_trial.params,\n",
    "        'metrics': study_gmm.best_trial.user_attrs.get('metrics', {})\n",
    "    }\n",
    "else:\n",
    "    meta['gmm'] = None\n",
    "\n",
    "# Save models & meta\n",
    "joblib.dump(kmeans_best, save_dir / 'kmeans_best_model.joblib')\n",
    "if 'gmm_best' in globals() and gmm_best is not None:\n",
    "    joblib.dump(gmm_best, save_dir / 'gmm_best_model.joblib')\n",
    "with open(save_dir / 'unsupervised_models_metadata.json', 'w') as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "print(f\"Saved artifacts to: {save_dir.resolve()}\")\n",
    "print(\"Files:\")\n",
    "for p in save_dir.glob('*model.joblib'):\n",
    "    print(' -', p.name)\n",
    "print(' - unsupervised_models_metadata.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c61deb3",
   "metadata": {},
   "source": [
    "### Loading Later\n",
    "```python\n",
    "import joblib, json\n",
    "kmeans = joblib.load('src/unsupervised/kmeans_best_model.joblib')\n",
    "try:\n",
    "    gmm = joblib.load('src/unsupervised/gmm_best_model.joblib')\n",
    "except FileNotFoundError:\n",
    "    gmm = None\n",
    "with open('src/unsupervised/unsupervised_models_metadata.json') as f:\n",
    "    meta = json.load(f)\n",
    "```\n",
    "The metadata file contains hyperparameters and validation metrics captured at save time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "milestone2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
