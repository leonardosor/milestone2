{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "731d278a",
   "metadata": {},
   "source": [
    "# Advanced Regression Pipeline: XGBoost, and Random Forest Comparison\n",
    "\n",
    "This notebook builds on the LightGBM pipeline to compare three regression algorithms using data from the local database. It includes data loading, preprocessing, model training, evaluation, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55439ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models will be saved to: D:\\docs\\MADS\\696-Milestone 2\\supervised\n",
      "LightGBM version: 4.6.0\n",
      "XGBoost version: 3.0.5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "## Environment\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "## Core Scientific Stack\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "## Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## Database\n",
    "import psycopg2\n",
    "\n",
    "## Machine Learning / Preprocessing (scikit-learn)\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PolynomialFeatures\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, Pipeline as SkPipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "## Gradient Boosting Libraries\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "## Deep Learning / Tabular\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "\n",
    "## Optimization & Persistence\n",
    "import optuna\n",
    "import joblib\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Setup model directory (handle notebook environment where __file__ is undefined)\n",
    "try:\n",
    "    PROJECT_ROOT = Path(__file__).resolve().parent\n",
    "except NameError:\n",
    "    # Fallback: assume notebook is inside src; go up one directory if so\n",
    "    cwd = Path.cwd().resolve()\n",
    "    if (cwd / 'supervised.ipynb').exists() or (cwd / 'unsupervised.ipynb').exists():\n",
    "        PROJECT_ROOT = cwd\n",
    "    else:\n",
    "        for parent in cwd.parents:\n",
    "            if (parent / 'requirements.txt').exists() or (parent / 'README.md').exists():\n",
    "                PROJECT_ROOT = parent / 'src'\n",
    "                break\n",
    "        else:\n",
    "            PROJECT_ROOT = cwd  # final fallback\n",
    "\n",
    "MODEL_DIR = (PROJECT_ROOT / '..' / 'supervised').resolve()\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Models will be saved to: {MODEL_DIR}\")\n",
    "\n",
    "def save_model(model, name: str, extra: dict | None = None):\n",
    "    \"\"\"Utility to persist models and optional metadata alongside them.\n",
    "    Saves model as joblib plus a companion JSON with metadata/hyperparams.\"\"\"\n",
    "    timestamp = datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')\n",
    "    base_name = f\"{name}_{timestamp}\"\n",
    "    model_path = MODEL_DIR / f\"{base_name}.joblib\"\n",
    "    meta_path = MODEL_DIR / f\"{base_name}.json\"\n",
    "    joblib.dump(model, model_path)\n",
    "    meta = {'model_name': name, 'saved_utc': timestamp}\n",
    "    if extra:\n",
    "        meta.update(extra)\n",
    "    with open(meta_path, 'w') as f:\n",
    "        json.dump(meta, f, indent=2)\n",
    "    print(f\"Saved model -> {model_path.name}; metadata -> {meta_path.name}\")\n",
    "\n",
    "# Database connection parameters\n",
    "db_params = {\n",
    "    \"host\": os.getenv(\"LOCAL_HOST\"),\n",
    "    \"user\": os.getenv(\"LOCAL_USER\"),\n",
    "    \"password\": os.getenv(\"LOCAL_PW\"),\n",
    "    \"port\": os.getenv(\"LOCAL_PORT\"),\n",
    "    \"dbname\": os.getenv(\"LOCAL_DB\")\n",
    "}\n",
    "\n",
    "# Display versions\n",
    "\n",
    "print('LightGBM version:', lgb.__version__)\n",
    "print('XGBoost version:', xgb.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fcae04",
   "metadata": {},
   "source": [
    "### Auto Load / Conditional Training\n",
    "If a previously saved optimized model exists in `src/supervised`, the notebook will load the most recent artifact (by timestamp in filename) and skip retraining unless `FORCE_RETRAIN=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fe517ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-load status (TabNet deferred):\n",
      "  xgb_model: pre-existing\n",
      "  rf_model: pre-existing\n",
      "  mlp_model: pre-existing\n",
      "  svr_model: pre-existing\n",
      "  lr_model: pre-existing\n",
      "  poly_model: pre-existing\n",
      "FORCE_RETRAIN= False\n"
     ]
    }
   ],
   "source": [
    "# Auto-load previously saved optimized models (XGBoost / RandomForest / SVR / LinearRegression / Polynomial / MLP / TabNet)\n",
    "from pathlib import Path as _Path\n",
    "import json as _json\n",
    "\n",
    "# Initialize placeholders if not already present\n",
    "globals().setdefault('FORCE_RETRAIN', False)\n",
    "\n",
    "# Only set to None if not defined to avoid clobbering models loaded earlier in session\n",
    "if 'xgb_model' not in globals():\n",
    "    xgb_model = None\n",
    "if 'rf_model' not in globals():\n",
    "    rf_model = None\n",
    "if 'mlp_model' not in globals():\n",
    "    mlp_model = None\n",
    "if 'tabnet_model' not in globals():\n",
    "    tabnet_model = None  # Will delay loading until wrapper class defined\n",
    "if 'svr_model' not in globals():\n",
    "    svr_model = None\n",
    "if 'lr_model' not in globals():\n",
    "    lr_model = None\n",
    "if 'poly_model' not in globals():\n",
    "    poly_model = None\n",
    "\n",
    "MODEL_GLOB_PATTERNS = {\n",
    "    'xgb_model': 'xgboost_opt_*.joblib',\n",
    "    'rf_model': 'random_forest_opt_*.joblib', \n",
    "    'mlp_model': 'mlp_opt_*.joblib', \n",
    "    # 'tabnet_model': 'tabnet_opt_*.joblib',  # DEFERRED: load after wrapper defined\n",
    "    'svr_model': 'svr_opt_*.joblib',\n",
    "    'lr_model': 'linear_regression_opt_*.joblib',\n",
    "    'poly_model': 'poly_reg_opt_*.joblib'\n",
    "}\n",
    "\n",
    "loaded_flags = {}\n",
    "for var, pattern in MODEL_GLOB_PATTERNS.items():\n",
    "    if globals().get(var) is not None:\n",
    "        loaded_flags[var] = 'pre-existing'\n",
    "        continue\n",
    "    matches = sorted(MODEL_DIR.glob(pattern))\n",
    "    if not matches:\n",
    "        loaded_flags[var] = 'not found'\n",
    "        continue\n",
    "    latest = matches[-1]\n",
    "    try:\n",
    "        globals()[var] = joblib.load(latest)\n",
    "        meta_file = latest.with_suffix('.json')\n",
    "        if meta_file.exists():\n",
    "            with open(meta_file) as f:\n",
    "                globals()[f\"{var}_meta\"] = _json.load(f)\n",
    "        loaded_flags[var] = f\"loaded {latest.name}\"\n",
    "    except Exception as e:\n",
    "        loaded_flags[var] = f\"failed: {e}\";\n",
    "        globals()[var] = None\n",
    "\n",
    "print(\"Auto-load status (TabNet deferred):\")\n",
    "for k,v in loaded_flags.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "print(\"FORCE_RETRAIN=\", FORCE_RETRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6177eaf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_25204\\3569683717.py:6: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(sql_query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Golden data loaded into DataFrame:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23038 entries, 0 to 23037\n",
      "Data columns (total 22 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   school_name             23038 non-null  object \n",
      " 1   school_type             23038 non-null  object \n",
      " 2   teachers_fte            22550 non-null  float64\n",
      " 3   enrollment              22863 non-null  float64\n",
      " 4   grade_eight_enrollment  21613 non-null  float64\n",
      " 5   math_counts             22507 non-null  float64\n",
      " 6   math_high_pct           22507 non-null  float64\n",
      " 7   math_low_pct            19960 non-null  float64\n",
      " 8   read_counts             22386 non-null  float64\n",
      " 9   read_high_pct           22386 non-null  float64\n",
      " 10  read_low_pct            19907 non-null  float64\n",
      " 11  pct_hhi_150k_200k       23038 non-null  float64\n",
      " 12  pct_hhi_220k_plus       23038 non-null  float64\n",
      " 13  avg_natwalkind          23038 non-null  float64\n",
      " 14  total_10_14             23038 non-null  int64  \n",
      " 15  pct_10_14               23038 non-null  int64  \n",
      " 16  pct_female_10_14        22937 non-null  float64\n",
      " 17  total_pop               23038 non-null  int64  \n",
      " 18  hhi_150k_200k           23038 non-null  int64  \n",
      " 19  hhi_220k_plus           23038 non-null  int64  \n",
      " 20  schools_in_zip          23038 non-null  int64  \n",
      " 21  dup_rank                23038 non-null  int64  \n",
      "dtypes: float64(13), int64(7), object(2)\n",
      "memory usage: 3.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Connect to database and load data\n",
    "try:\n",
    "    conn = psycopg2.connect(**db_params)\n",
    "    print(\"Database connection successful\")\n",
    "    sql_query = \"SELECT * FROM dev.golden_table;\"\n",
    "    df = pd.read_sql_query(sql_query, conn)\n",
    "    conn.close()\n",
    "    print(\"Golden data loaded into DataFrame:\")\n",
    "    print(df.info())\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd6bcca",
   "metadata": {},
   "source": [
    "## 3. Data Splitting: Train, Validation, Test\n",
    "Split the dataset into train, validation, and test sets, ensuring proper handling of the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13df7dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (11367, 16), Validation shape: (3789, 16), Test shape: (3789, 16)\n"
     ]
    }
   ],
   "source": [
    "# Define target and drop missing\n",
    "TARGET = 'math_high_pct' if 'math_high_pct' in df.columns else 'target'\n",
    "data = df.dropna().reset_index(drop=True)\n",
    "drop_cols = ['hhi_150k_200k', 'hhi_220k_plus','total_10_14']\n",
    "data = data.drop(columns=drop_cols)\n",
    "data = data.set_index('school_name')\n",
    "\n",
    "# Split features and target\n",
    "feature_cols = [c for c in data.columns if c != TARGET and c != 'dup_rank']\n",
    "X = data[feature_cols]\n",
    "y = data[TARGET]\n",
    "\n",
    "# Train/validation/test split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.40, random_state=42)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42)\n",
    "print(f'Train shape: {X_train.shape}, Validation shape: {X_valid.shape}, Test shape: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b52296",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering and Preprocessing Pipeline\n",
    "Identify numeric and categorical features, set up StandardScaler and OneHotEncoder, and build a ColumnTransformer pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20c071ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features: ['teachers_fte', 'enrollment', 'grade_eight_enrollment', 'math_counts', 'math_low_pct', 'read_counts', 'read_high_pct', 'read_low_pct', 'pct_hhi_150k_200k', 'pct_hhi_220k_plus', 'avg_natwalkind', 'pct_10_14', 'pct_female_10_14', 'total_pop', 'schools_in_zip']\n",
      "Categorical features: ['school_type']\n"
     ]
    }
   ],
   "source": [
    "# Identify numeric and categorical features\n",
    "numeric_features = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_features = X_train.select_dtypes(include=['category', 'object']).columns.tolist()\n",
    "\n",
    "print('Numeric features:', numeric_features)\n",
    "print('Categorical features:', categorical_features)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# Fit preprocessor\n",
    "preprocessor.fit(X_train)\n",
    "X_train_enc = preprocessor.transform(X_train)\n",
    "X_valid_enc = preprocessor.transform(X_valid)\n",
    "X_test_enc = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6187ca5",
   "metadata": {},
   "source": [
    "## Model Optimization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92bc1731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reusable Optuna-based optimizer for cross-validated hyperparameter tuning\n",
    "from typing import Callable, Dict, Tuple\n",
    "\n",
    "def optimize_model_with_optuna(\n",
    "                                model_name: str,\n",
    "                                estimator_builder: Callable[[Dict], object],\n",
    "                                param_space_fn: Callable[[optuna.trial.Trial], Dict],\n",
    "                                X,\n",
    "                                y,\n",
    "                                scoring: str = 'neg_root_mean_squared_error',\n",
    "                                cv: int = 3,\n",
    "                                n_trials: int = 5,\n",
    "                                direction: str = 'minimize',\n",
    "                                random_state: int = 42,\n",
    "                                n_jobs: int = -1,\n",
    "                            ) -> Tuple[optuna.study.Study, Dict]:\n",
    "    \"\"\"Optimize a model's hyperparameters using Optuna and cross-validation.\n",
    "\n",
    "    Args:\n",
    "        model_name: Name used to label the Optuna study\n",
    "        estimator_builder: Callable that receives a params dict and returns an unfitted estimator\n",
    "        param_space_fn: Callable that maps an Optuna trial to a hyperparameter dictionary\n",
    "        X, y: Training features and targets used for cross-validation\n",
    "        scoring: scikit-learn scoring string guiding optimization\n",
    "        cv: Number of cross-validation folds\n",
    "        n_trials: Number of Optuna trials to run\n",
    "        direction: 'minimize' or 'maximize' depending on the objective\n",
    "        random_state: Seed for the Optuna sampler\n",
    "        n_jobs: Parallelism for cross_val_score\n",
    "\n",
    "    Returns:\n",
    "        The completed Optuna study and the best hyperparameters discovered.\n",
    "    \"\"\"\n",
    "    sampler = optuna.samplers.TPESampler(seed=random_state)\n",
    "    study = optuna.create_study(study_name=f\"{model_name}_opt\", direction=direction, sampler=sampler)\n",
    "\n",
    "    def objective(trial: optuna.trial.Trial) -> float:\n",
    "        params = param_space_fn(trial)\n",
    "        estimator = estimator_builder(params)\n",
    "        scores = cross_val_score(estimator, X, y, cv=cv, scoring=scoring, n_jobs=n_jobs)\n",
    "        mean_score = np.mean(scores)\n",
    "        normalized_score = -mean_score if scoring.startswith('neg') else mean_score\n",
    "        return normalized_score if direction == 'minimize' else -normalized_score\n",
    "\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
    "    return study, study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d6bcf7",
   "metadata": {},
   "source": [
    "## Model metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d533b035",
   "metadata": {},
   "source": [
    "## LINEAR MODELS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c2c6c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SVR] Using preloaded optimized model; generating predictions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 10:15:39,164] A new study created in memory with name: PolynomialRegression_opt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PolynomialRegression] Starting Optuna optimization...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d988f16f6248e49ad2a443d70f4e1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 10:15:46,883] Trial 0 finished with value: 4937230285.657545 and parameters: {'degree': 3, 'interaction_only': False}. Best is trial 0 with value: 4937230285.657545.\n",
      "[I 2025-10-06 10:23:42,664] Trial 1 finished with value: 14761702710.802286 and parameters: {'degree': 4, 'interaction_only': False}. Best is trial 0 with value: 4937230285.657545.\n",
      "[I 2025-10-06 10:23:42,664] Trial 1 finished with value: 14761702710.802286 and parameters: {'degree': 4, 'interaction_only': False}. Best is trial 0 with value: 4937230285.657545.\n",
      "[I 2025-10-06 10:23:43,103] Trial 2 finished with value: 377312545695.4566 and parameters: {'degree': 2, 'interaction_only': False}. Best is trial 0 with value: 4937230285.657545.\n",
      "[I 2025-10-06 10:23:43,103] Trial 2 finished with value: 377312545695.4566 and parameters: {'degree': 2, 'interaction_only': False}. Best is trial 0 with value: 4937230285.657545.\n",
      "[I 2025-10-06 10:26:41,201] Trial 3 finished with value: 281993117177.21075 and parameters: {'degree': 4, 'interaction_only': True}. Best is trial 0 with value: 4937230285.657545.\n",
      "[I 2025-10-06 10:26:41,201] Trial 3 finished with value: 281993117177.21075 and parameters: {'degree': 4, 'interaction_only': True}. Best is trial 0 with value: 4937230285.657545.\n",
      "[I 2025-10-06 10:38:47,532] Trial 4 finished with value: 236737473.45793906 and parameters: {'degree': 5, 'interaction_only': False}. Best is trial 4 with value: 236737473.45793906.\n",
      "Best Polynomial Regression params: {'degree': 5, 'interaction_only': False}\n",
      "[I 2025-10-06 10:38:47,532] Trial 4 finished with value: 236737473.45793906 and parameters: {'degree': 5, 'interaction_only': False}. Best is trial 4 with value: 236737473.45793906.\n",
      "Best Polynomial Regression params: {'degree': 5, 'interaction_only': False}\n",
      "Saved model -> poly_reg_opt_20251006T145043Z.joblib; metadata -> poly_reg_opt_20251006T145043Z.json\n",
      "Saved model -> poly_reg_opt_20251006T145043Z.joblib; metadata -> poly_reg_opt_20251006T145043Z.json\n"
     ]
    }
   ],
   "source": [
    "# Linear & Kernel-based Models: SVR + Polynomial Regression (with Optuna tuning + CV)\n",
    "def build_svr_estimator(params: Dict) -> SVR:\n",
    "    base = {'kernel': params.get('kernel', 'rbf')}\n",
    "    # Map params safely\n",
    "    for k in ['C','epsilon','gamma','degree']:\n",
    "        if k in params:\n",
    "            base[k] = params[k]\n",
    "    return SVR(**base)\n",
    "\n",
    "def svr_param_space(trial: optuna.trial.Trial) -> Dict:\n",
    "    kernel = trial.suggest_categorical('kernel', ['rbf','poly','sigmoid'])\n",
    "    params = {\n",
    "        'kernel': kernel,\n",
    "        'C': trial.suggest_float('C', 1e-1, 1e3, log=True),\n",
    "        'epsilon': trial.suggest_float('epsilon', 1e-3, 0.5, log=True)\n",
    "    }\n",
    "    if kernel in ['rbf','sigmoid']:\n",
    "        params['gamma'] = trial.suggest_float('gamma', 1e-4, 1, log=True)\n",
    "    if kernel == 'poly':\n",
    "        params['degree'] = trial.suggest_int('degree', 2, 5)\n",
    "        params['gamma'] = trial.suggest_float('gamma', 1e-4, 1, log=True)\n",
    "    return params\n",
    "\n",
    "def build_poly_estimator(params: Dict):\n",
    "    degree = params.get('degree', 2)\n",
    "    include_bias = params.get('include_bias', False)\n",
    "    interaction_only = params.get('interaction_only', False)\n",
    "    return SkPipeline([\n",
    "        ('poly', PolynomialFeatures(degree=degree, include_bias=include_bias, interaction_only=interaction_only)),\n",
    "        ('lr', LinearRegression())\n",
    "    ])\n",
    "\n",
    "def poly_param_space(trial: optuna.trial.Trial) -> Dict:\n",
    "    return {\n",
    "        'degree': trial.suggest_int('degree', 2, 5),\n",
    "        'include_bias': False,\n",
    "        'interaction_only': trial.suggest_categorical('interaction_only', [False, True])\n",
    "    }\n",
    "\n",
    "# Run / reuse SVR optimization\n",
    "if svr_model is None or FORCE_RETRAIN:\n",
    "    print('[SVR] Starting Optuna optimization...')\n",
    "    svr_study, svr_best_params = optimize_model_with_optuna(\n",
    "        model_name='SVR',\n",
    "        estimator_builder=build_svr_estimator,\n",
    "        param_space_fn=svr_param_space,\n",
    "        X=X_train_enc,\n",
    "        y=y_train,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        cv=3,\n",
    "        n_trials=5,\n",
    "        direction='minimize',\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    print('Best SVR params:', svr_best_params)\n",
    "    svr_model = build_svr_estimator(svr_best_params)\n",
    "    svr_model.fit(X_train_enc, y_train)\n",
    "    svr_valid_pred = svr_model.predict(X_valid_enc)\n",
    "    svr_test_pred = svr_model.predict(X_test_enc)\n",
    "    save_model(svr_model, 'svr_opt', {'best_params': svr_best_params})\n",
    "else:\n",
    "    print('[SVR] Using preloaded optimized model; generating predictions.')\n",
    "    svr_valid_pred = svr_model.predict(X_valid_enc)\n",
    "    svr_test_pred = svr_model.predict(X_test_enc)\n",
    "\n",
    "# Baseline Linear Regression (also optionally re-optimized via polynomial)\n",
    "if lr_model is None and poly_model is None:\n",
    "    # Keep a simple baseline linear regression for reference\n",
    "    lr_model = LinearRegression()\n",
    "    lr_model.fit(X_train_enc, y_train)\n",
    "    save_model(lr_model, 'linear_regression_opt', {'params': lr_model.get_params(), 'baseline': True})\n",
    "    lr_valid_pred = lr_model.predict(X_valid_enc)\n",
    "    lr_test_pred = lr_model.predict(X_test_enc)\n",
    "elif lr_model is not None:\n",
    "    lr_valid_pred = lr_model.predict(X_valid_enc)\n",
    "    lr_test_pred = lr_model.predict(X_test_enc)\n",
    "\n",
    "# Polynomial Regression optimization\n",
    "if poly_model is None or FORCE_RETRAIN:\n",
    "    print('[PolynomialRegression] Starting Optuna optimization...')\n",
    "    poly_study, poly_best_params = optimize_model_with_optuna(\n",
    "        model_name='PolynomialRegression',\n",
    "        estimator_builder=build_poly_estimator,\n",
    "        param_space_fn=poly_param_space,\n",
    "        X=X_train_enc,\n",
    "        y=y_train,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        cv=3,\n",
    "        n_trials=5,\n",
    "        direction='minimize',\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    print('Best Polynomial Regression params:', poly_best_params)\n",
    "    poly_model = build_poly_estimator(poly_best_params)\n",
    "    poly_model.fit(X_train_enc, y_train)\n",
    "    poly_valid_pred = poly_model.predict(X_valid_enc)\n",
    "    poly_test_pred = poly_model.predict(X_test_enc)\n",
    "    save_model(poly_model, 'poly_reg_opt', {'best_params': poly_best_params})\n",
    "else:\n",
    "    print('[PolynomialRegression] Using preloaded optimized model; generating predictions.')\n",
    "    poly_valid_pred = poly_model.predict(X_valid_enc)\n",
    "    poly_test_pred = poly_model.predict(X_test_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdf134e",
   "metadata": {},
   "source": [
    "# NEURAL NETWORKS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58546626",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "745b1e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 11:51:49,263] A new study created in memory with name: TorchMLPRegressor_opt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TorchMLP] No preloaded model (or FORCE_RETRAIN=True). Starting Optuna optimization on CPU\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc579b42113f46b5b5b3f633ca7b026d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 11:52:14,379] Trial 0 finished with value: 12.283570654990045 and parameters: {'hl1': 128, 'hl2': 192, 'learning_rate_init': 0.0029106359131330704, 'alpha': 0.0002481040974867811, 'batch_size': 64, 'max_iter': 600, 'n_iter_no_change': 20, 'activation': 'relu'}. Best is trial 0 with value: 12.283570654990045.\n",
      "[I 2025-10-06 11:52:46,646] Trial 1 finished with value: 12.345241395345903 and parameters: {'hl1': 256, 'hl2': 160, 'learning_rate_init': 0.00026587543983272726, 'alpha': 5.337032762603957e-06, 'batch_size': 256, 'max_iter': 375, 'n_iter_no_change': 10, 'activation': 'relu'}. Best is trial 0 with value: 12.283570654990045.\n",
      "[I 2025-10-06 11:52:46,646] Trial 1 finished with value: 12.345241395345903 and parameters: {'hl1': 256, 'hl2': 160, 'learning_rate_init': 0.00026587543983272726, 'alpha': 5.337032762603957e-06, 'batch_size': 256, 'max_iter': 375, 'n_iter_no_change': 10, 'activation': 'relu'}. Best is trial 0 with value: 12.283570654990045.\n",
      "[I 2025-10-06 11:53:00,999] Trial 2 finished with value: 12.239693041610112 and parameters: {'hl1': 128, 'hl2': 96, 'learning_rate_init': 0.000816845589476017, 'alpha': 0.0013826232179369874, 'batch_size': 256, 'max_iter': 150, 'n_iter_no_change': 20, 'activation': 'relu'}. Best is trial 2 with value: 12.239693041610112.\n",
      "[I 2025-10-06 11:53:00,999] Trial 2 finished with value: 12.239693041610112 and parameters: {'hl1': 128, 'hl2': 96, 'learning_rate_init': 0.000816845589476017, 'alpha': 0.0013826232179369874, 'batch_size': 256, 'max_iter': 150, 'n_iter_no_change': 20, 'activation': 'relu'}. Best is trial 2 with value: 12.239693041610112.\n",
      "[I 2025-10-06 11:53:12,564] Trial 3 finished with value: 11.607611009425261 and parameters: {'hl1': 256, 'hl2': 192, 'learning_rate_init': 0.004138040112561018, 'alpha': 1.6536937182824424e-05, 'batch_size': 128, 'max_iter': 150, 'n_iter_no_change': 15, 'activation': 'tanh'}. Best is trial 3 with value: 11.607611009425261.\n",
      "[I 2025-10-06 11:53:12,564] Trial 3 finished with value: 11.607611009425261 and parameters: {'hl1': 256, 'hl2': 192, 'learning_rate_init': 0.004138040112561018, 'alpha': 1.6536937182824424e-05, 'batch_size': 128, 'max_iter': 150, 'n_iter_no_change': 15, 'activation': 'tanh'}. Best is trial 3 with value: 11.607611009425261.\n",
      "[I 2025-10-06 11:53:45,651] Trial 4 finished with value: 12.195046232688918 and parameters: {'hl1': 96, 'hl2': 128, 'learning_rate_init': 0.0004201672054372534, 'alpha': 0.00012030178871154674, 'batch_size': 256, 'max_iter': 525, 'n_iter_no_change': 25, 'activation': 'relu'}. Best is trial 3 with value: 11.607611009425261.\n",
      "Best TorchMLP params: {'hl1': 256, 'hl2': 192, 'learning_rate_init': 0.004138040112561018, 'alpha': 1.6536937182824424e-05, 'batch_size': 128, 'max_iter': 150, 'n_iter_no_change': 15, 'activation': 'tanh'}\n",
      "[TorchMLP] Training on device: cpu\n",
      "[I 2025-10-06 11:53:45,651] Trial 4 finished with value: 12.195046232688918 and parameters: {'hl1': 96, 'hl2': 128, 'learning_rate_init': 0.0004201672054372534, 'alpha': 0.00012030178871154674, 'batch_size': 256, 'max_iter': 525, 'n_iter_no_change': 25, 'activation': 'relu'}. Best is trial 3 with value: 11.607611009425261.\n",
      "Best TorchMLP params: {'hl1': 256, 'hl2': 192, 'learning_rate_init': 0.004138040112561018, 'alpha': 1.6536937182824424e-05, 'batch_size': 128, 'max_iter': 150, 'n_iter_no_change': 15, 'activation': 'tanh'}\n",
      "[TorchMLP] Training on device: cpu\n",
      "Saved model -> mlp_opt_20251006T155400Z.joblib; metadata -> mlp_opt_20251006T155400Z.json\n",
      "Saved model -> mlp_opt_20251006T155400Z.joblib; metadata -> mlp_opt_20251006T155400Z.json\n"
     ]
    }
   ],
   "source": [
    "# Torch-based MLP (CUDA-enabled) + TabNet parameter spaces and optimization hooks\n",
    "\n",
    "def _ensure_dense_np(X):\n",
    "    # ColumnTransformer output may be sparse\n",
    "    if hasattr(X, 'toarray'):\n",
    "        return X.toarray()\n",
    "    return X\n",
    "\n",
    "def _set_torch_seed(seed: int):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "class TorchMLPRegressor(BaseEstimator, RegressorMixin):\n",
    "    \"\"\"A lightweight PyTorch MLP for regression with sklearn API.\n",
    "\n",
    "    Supports:\n",
    "      - hidden_layer_sizes: tuple of ints\n",
    "      - activation: 'relu' | 'tanh'\n",
    "      - learning_rate_init: float (alias learning_rate)\n",
    "      - alpha: L2 weight decay\n",
    "      - batch_size, max_iter (epochs)\n",
    "      - early_stopping with validation split + patience (n_iter_no_change)\n",
    "      - CUDA automatically if available (override via device)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_layer_sizes: Tuple[int, ...] = (128, 64),\n",
    "        activation: str = 'relu',\n",
    "        learning_rate_init: float = 1e-3,\n",
    "        alpha: float = 0.0,\n",
    "        batch_size: int = 128,\n",
    "        max_iter: int = 100,\n",
    "        early_stopping: bool = True,\n",
    "        validation_fraction: float = 0.1,\n",
    "        n_iter_no_change: int = 15,\n",
    "        random_state: int = 42,\n",
    "        verbose: bool = False,\n",
    "        device: str | None = None,\n",
    "    ):\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        self.activation = activation\n",
    "        self.learning_rate_init = learning_rate_init\n",
    "        self.alpha = alpha\n",
    "        self.batch_size = batch_size\n",
    "        self.max_iter = max_iter\n",
    "        self.early_stopping = early_stopping\n",
    "        self.validation_fraction = validation_fraction\n",
    "        self.n_iter_no_change = n_iter_no_change\n",
    "        self.random_state = random_state\n",
    "        self.verbose = verbose\n",
    "        self.device = device  # 'cuda' | 'cpu' | None\n",
    "\n",
    "    def get_params(self, deep=True):  # needed for sklearn clone\n",
    "        return {\n",
    "            'hidden_layer_sizes': self.hidden_layer_sizes,\n",
    "            'activation': self.activation,\n",
    "            'learning_rate_init': self.learning_rate_init,\n",
    "            'alpha': self.alpha,\n",
    "            'batch_size': self.batch_size,\n",
    "            'max_iter': self.max_iter,\n",
    "            'early_stopping': self.early_stopping,\n",
    "            'validation_fraction': self.validation_fraction,\n",
    "            'n_iter_no_change': self.n_iter_no_change,\n",
    "            'random_state': self.random_state,\n",
    "            'verbose': self.verbose,\n",
    "            'device': self.device,\n",
    "        }\n",
    "\n",
    "    def set_params(self, **params):  # compatibility\n",
    "        for k, v in params.items():\n",
    "            setattr(self, k, v)\n",
    "        return self\n",
    "\n",
    "    def _build_network(self, in_features: int):\n",
    "        layers: list[nn.Module] = []\n",
    "        prev = in_features\n",
    "        act_map = {'relu': nn.ReLU, 'tanh': nn.Tanh}\n",
    "        Act = act_map.get(self.activation.lower(), nn.ReLU)\n",
    "        for h in self.hidden_layer_sizes:\n",
    "            layers.append(nn.Linear(prev, h))\n",
    "            layers.append(Act())\n",
    "            prev = h\n",
    "        layers.append(nn.Linear(prev, 1))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        _set_torch_seed(self.random_state)\n",
    "        X_np = _ensure_dense_np(X).astype('float32')\n",
    "        y_np = (y.values if hasattr(y, 'values') else y).astype('float32').reshape(-1, 1)\n",
    "        n_samples = X_np.shape[0]\n",
    "        # Validation split\n",
    "        if self.early_stopping and 0 < self.validation_fraction < 0.5 and n_samples > 20:\n",
    "            val_size = max(1, int(n_samples * self.validation_fraction))\n",
    "            idx = np.arange(n_samples)\n",
    "            rng = np.random.default_rng(self.random_state)\n",
    "            rng.shuffle(idx)\n",
    "            val_idx = idx[:val_size]\n",
    "            train_idx = idx[val_size:]\n",
    "            X_train, y_train = X_np[train_idx], y_np[train_idx]\n",
    "            X_val, y_val = X_np[val_idx], y_np[val_idx]\n",
    "        else:\n",
    "            X_train, y_train = X_np, y_np\n",
    "            X_val, y_val = None, None\n",
    "        device = self.device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self._device_ = device\n",
    "        # Explicit device print for visibility\n",
    "        print(f\"[TorchMLP] Training on device: {device}\")\n",
    "        self.model_ = self._build_network(X_np.shape[1]).to(device)\n",
    "        self.optimizer_ = torch.optim.Adam(self.model_.parameters(), lr=self.learning_rate_init, weight_decay=self.alpha)\n",
    "        self.criterion_ = nn.MSELoss()\n",
    "        train_ds = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
    "        train_loader = DataLoader(train_ds, batch_size=self.batch_size, shuffle=True)\n",
    "        if X_val is not None:\n",
    "            val_tensor = torch.from_numpy(X_val).to(device)\n",
    "            y_val_tensor = torch.from_numpy(y_val).to(device)\n",
    "        best_val = math.inf\n",
    "        best_state = None\n",
    "        rounds_no_improve = 0\n",
    "        for epoch in range(1, self.max_iter + 1):\n",
    "            self.model_.train()\n",
    "            epoch_loss = 0.0\n",
    "            for xb, yb in train_loader:\n",
    "                xb = xb.to(device)\n",
    "                yb = yb.to(device)\n",
    "                self.optimizer_.zero_grad()\n",
    "                pred = self.model_(xb)\n",
    "                loss = self.criterion_(pred, yb)\n",
    "                loss.backward()\n",
    "                self.optimizer_.step()\n",
    "                epoch_loss += loss.item() * xb.size(0)\n",
    "            epoch_loss /= len(train_loader.dataset)\n",
    "            if X_val is not None:\n",
    "                self.model_.eval()\n",
    "                with torch.no_grad():\n",
    "                    val_pred = self.model_(val_tensor)\n",
    "                    val_loss = self.criterion_(val_pred, y_val_tensor).item()\n",
    "                improved = val_loss + 1e-9 < best_val\n",
    "                if improved:\n",
    "                    best_val = val_loss\n",
    "                    best_state = {k: v.cpu().clone() for k, v in self.model_.state_dict().items()}\n",
    "                    rounds_no_improve = 0\n",
    "                else:\n",
    "                    rounds_no_improve += 1\n",
    "                if self.verbose and (epoch % 10 == 0 or improved):\n",
    "                    print(f\"Epoch {epoch:03d} train_loss={epoch_loss:.4f} val_loss={val_loss:.4f} best_val={best_val:.4f}\")\n",
    "                if self.early_stopping and rounds_no_improve >= self.n_iter_no_change:\n",
    "                    if self.verbose:\n",
    "                        print(f\"Early stopping at epoch {epoch}\")\n",
    "                    break\n",
    "            else:\n",
    "                if self.verbose and epoch % 10 == 0:\n",
    "                    print(f\"Epoch {epoch:03d} train_loss={epoch_loss:.4f}\")\n",
    "        # Load best validation weights\n",
    "        if best_state is not None:\n",
    "            self.model_.load_state_dict(best_state)\n",
    "        self.n_features_in_ = X_np.shape[1]\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        check_is_fitted(self, ['model_'])\n",
    "        X_np = _ensure_dense_np(X).astype('float32')\n",
    "        device = self._device_\n",
    "        self.model_.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model_(torch.from_numpy(X_np).to(device))\n",
    "        return preds.cpu().numpy().ravel()\n",
    "\n",
    "def build_mlp_estimator(params: Dict) -> TorchMLPRegressor:\n",
    "    \"\"\"Return a TorchMLPRegressor; map sklearn-style names used in param space.\n",
    "    Removes Optuna helper keys hl1/hl2 before constructing.\"\"\"\n",
    "    params = params.copy()\n",
    "    params.pop('hl1', None)\n",
    "    params.pop('hl2', None)\n",
    "    return TorchMLPRegressor(**params)\n",
    "\n",
    "def mlp_param_space(trial: optuna.trial.Trial) -> Dict:\n",
    "    return {\n",
    "        'hidden_layer_sizes': tuple(sorted([\n",
    "            trial.suggest_int('hl1', 64, 256, step=32),\n",
    "            trial.suggest_int('hl2', 32, 192, step=32)\n",
    "        ], reverse=True)),\n",
    "        'learning_rate_init': trial.suggest_float('learning_rate_init', 1e-4, 1e-2, log=True),\n",
    "        'alpha': trial.suggest_float('alpha', 1e-6, 1e-2, log=True),  # weight decay\n",
    "        'batch_size': trial.suggest_categorical('batch_size', [64, 128, 256]),\n",
    "        'max_iter': trial.suggest_int('max_iter', 150, 600, step=75),\n",
    "        'n_iter_no_change': trial.suggest_int('n_iter_no_change', 5, 25, step=5),\n",
    "        'early_stopping': True,\n",
    "        'validation_fraction': 0.15,\n",
    "        'activation': trial.suggest_categorical('activation', ['relu', 'tanh']),\n",
    "        'random_state': 42,\n",
    "        'verbose': False,\n",
    "    }\n",
    "\n",
    "# Run / reuse MLP optimization\n",
    "if mlp_model is None or FORCE_RETRAIN:\n",
    "    print(\"[TorchMLP] No preloaded model (or FORCE_RETRAIN=True). Starting Optuna optimization on\", ('CUDA' if torch.cuda.is_available() else 'CPU'))\n",
    "    mlp_study, mlp_best_params = optimize_model_with_optuna(\n",
    "        model_name='TorchMLPRegressor',\n",
    "        estimator_builder=build_mlp_estimator,\n",
    "        param_space_fn=mlp_param_space,\n",
    "        X=X_train_enc,\n",
    "        y=y_train,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        cv=3,\n",
    "        n_trials=5,\n",
    "        direction='minimize',\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    print('Best TorchMLP params:', mlp_best_params)\n",
    "    mlp_model = build_mlp_estimator(mlp_best_params)\n",
    "    mlp_model.fit(X_train_enc, y_train)\n",
    "    mlp_valid_pred = mlp_model.predict(X_valid_enc)\n",
    "    mlp_test_pred = mlp_model.predict(X_test_enc)\n",
    "    save_model(mlp_model, 'mlp_opt', {'best_params': mlp_best_params, 'framework': 'torch'})\n",
    "else:\n",
    "    # Refitting even when a model was preloaded to align with current dataset / preprocessing state\n",
    "    print(\"[TorchMLP] Preloaded model found; refitting on current data to refresh weights and predictions.\")\n",
    "    # Attempt to reuse stored best params if they exist on the object; else use its own get_params()\n",
    "    try:\n",
    "        existing_params = {k: v for k, v in mlp_model.get_params().items() if k in TorchMLPRegressor().get_params()}\n",
    "    except Exception:\n",
    "        existing_params = {}\n",
    "    mlp_model = build_mlp_estimator(existing_params) if existing_params else mlp_model\n",
    "    mlp_model.fit(X_train_enc, y_train)\n",
    "    mlp_valid_pred = mlp_model.predict(X_valid_enc)\n",
    "    mlp_test_pred = mlp_model.predict(X_test_enc)\n",
    "    # Optionally save refit (comment out if not desired)\n",
    "    save_model(mlp_model, 'mlp_opt_refit', {'refit': True, 'framework': 'torch'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484b7801",
   "metadata": {},
   "source": [
    "## TABNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a3270f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TabNet] Late-loaded saved model: tabnet_opt_refit_20251005T212433Z.joblib\n",
      "[TabNet] Using loaded model; refitting on current data (FAST_TABNET=True).\n",
      "Stop training because you reached max_epochs = 120 with best_epoch = 108 and best_val_0_rmse = 10.15413\n",
      "Stop training because you reached max_epochs = 120 with best_epoch = 108 and best_val_0_rmse = 10.15413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Leo\\miniconda3\\envs\\milestone2\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model -> tabnet_opt_refit_20251006T155735Z.joblib; metadata -> tabnet_opt_refit_20251006T155735Z.json\n"
     ]
    }
   ],
   "source": [
    "def _to_float32_dense(X):\n",
    "    return X.toarray().astype(np.float32) if hasattr(X, 'toarray') else np.asarray(X, dtype=np.float32)\n",
    "\n",
    "# Speed/behavior flags\n",
    "globals().setdefault('FAST_TABNET', True)  # Toggle this to False for full/slow training\n",
    "\n",
    "class TabNetRegressorWrapper(BaseEstimator, RegressorMixin):\n",
    "    \"\"\"A scikit-learn compatible wrapper for TabNetRegressor with fast-mode support.\n",
    "\n",
    "    Features:\n",
    "      - Converts sparse inputs to dense float32\n",
    "      - Reshapes y to (n,1) as required by TabNet\n",
    "      - Internal validation split (validation_fraction) enabling effective early stopping\n",
    "      - Fast mode reducing epochs, patience, and search space for quicker experimentation\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 max_epochs=200,\n",
    "                 patience=50,\n",
    "                 batch_size=1024,\n",
    "                 virtual_batch_size=128,\n",
    "                 eval_metric='rmse',\n",
    "                 validation_fraction: float = 0.15,\n",
    "                 seed=42,\n",
    "                 verbose=0,\n",
    "                 fast: bool | None = None,\n",
    "                 **tabnet_params):\n",
    "        self.max_epochs = max_epochs\n",
    "        self.patience = patience\n",
    "        self.batch_size = batch_size\n",
    "        self.virtual_batch_size = virtual_batch_size\n",
    "        self.eval_metric = eval_metric if isinstance(eval_metric, (list, tuple)) else [eval_metric]\n",
    "        self.validation_fraction = validation_fraction\n",
    "        self.seed = seed\n",
    "        self.verbose = verbose\n",
    "        self.fast = FAST_TABNET if fast is None else fast\n",
    "        self.tabnet_params = tabnet_params\n",
    "        self.model_ = None\n",
    "\n",
    "    def _to_dense32(self, X):\n",
    "        return _to_float32_dense(X)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        Xd = self._to_dense32(X)\n",
    "        y_arr = np.asarray(y)\n",
    "        if y_arr.ndim == 1:\n",
    "            y_arr = y_arr.reshape(-1, 1)\n",
    "        n = Xd.shape[0]\n",
    "        # Internal validation split for genuine early stopping\n",
    "        if 0 < self.validation_fraction < 0.5 and n > 30:\n",
    "            val_size = max(1, int(n * self.validation_fraction))\n",
    "            rng = np.random.default_rng(self.seed)\n",
    "            idx = rng.permutation(n)\n",
    "            val_idx = idx[:val_size]\n",
    "            train_idx = idx[val_size:]\n",
    "            X_train, y_train = Xd[train_idx], y_arr[train_idx]\n",
    "            X_val, y_val = Xd[val_idx], y_arr[val_idx]\n",
    "            eval_set = [(X_val, y_val)]\n",
    "        else:\n",
    "            X_train, y_train = Xd, y_arr\n",
    "            eval_set = [(Xd, y_arr)]\n",
    "        # Adjust hyperparameters in fast mode (applies only at fit time)\n",
    "        max_epochs = min(self.max_epochs, 120 if self.fast else self.max_epochs)\n",
    "        patience = min(self.patience, 25 if self.fast else self.patience)\n",
    "        if self.fast and self.verbose:\n",
    "            print(f\"[TabNetWrapper] FAST mode active: max_epochs={max_epochs}, patience={patience}\")\n",
    "        self.model_ = TabNetRegressor(seed=self.seed, verbose=self.verbose, **self.tabnet_params)\n",
    "        self.model_.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            eval_set=eval_set,\n",
    "            eval_metric=self.eval_metric,\n",
    "            patience=patience,\n",
    "            max_epochs=max_epochs,\n",
    "            batch_size=self.batch_size,\n",
    "            virtual_batch_size=self.virtual_batch_size,\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        check_is_fitted(self, 'model_')\n",
    "        Xd = self._to_dense32(X)\n",
    "        preds = self.model_.predict(Xd)\n",
    "        return preds.ravel()\n",
    "\n",
    "\n",
    "def build_tabnet_estimator(params: Dict) -> TabNetRegressorWrapper:\n",
    "    \"\"\"Return a TabNetRegressorWrapper with defaults merged with tuned params.\"\"\"\n",
    "    defaults = dict(\n",
    "        n_d=16, n_a=16, n_steps=5, gamma=1.3,\n",
    "        lambda_sparse=1e-4,\n",
    "        optimizer_params={'lr': 2e-2},\n",
    "    )\n",
    "    defaults.update(params)\n",
    "    training_keys = ['max_epochs', 'patience', 'batch_size', 'virtual_batch_size', 'validation_fraction', 'fast']\n",
    "    training_overrides = {k: defaults.pop(k) for k in list(defaults.keys()) if k in training_keys}\n",
    "    return TabNetRegressorWrapper(**training_overrides, **defaults)\n",
    "\n",
    "\n",
    "def tabnet_param_space(trial: optuna.trial.Trial) -> Dict:\n",
    "    \"\"\"Reduced/narrower search space for faster optimization when FAST_TABNET is True.\"\"\"\n",
    "    fast = FAST_TABNET\n",
    "    return {\n",
    "        'n_d': trial.suggest_categorical('n_d', [8, 16, 24] if fast else [8, 16, 24, 32]),\n",
    "        'n_a': trial.suggest_categorical('n_a', [8, 16, 24] if fast else [8, 16, 24, 32]),\n",
    "        'n_steps': trial.suggest_int('n_steps', 3, 6 if fast else 8),\n",
    "        'gamma': trial.suggest_float('gamma', 1.0, 1.8 if fast else 2.0),\n",
    "        'lambda_sparse': trial.suggest_float('lambda_sparse', 1e-6, 5e-4 if fast else 1e-3, log=True),\n",
    "        'optimizer_params': {'lr': trial.suggest_float('lr', 1e-3, 2e-2 if fast else 5e-2, log=True)},\n",
    "        'max_epochs': 100 if fast else 200,\n",
    "        'patience': 20 if fast else 50,\n",
    "        'batch_size': 1024,\n",
    "        'virtual_batch_size': 128,\n",
    "        'validation_fraction': 0.15,\n",
    "        'fast': fast,\n",
    "    }\n",
    "\n",
    "# Late-load TabNet model now that wrapper class exists (if not already loaded)\n",
    "if tabnet_model is None and not FORCE_RETRAIN:\n",
    "    tabnet_matches = sorted(MODEL_DIR.glob('tabnet_opt_*.joblib'))\n",
    "    if tabnet_matches:\n",
    "        latest_tabnet = tabnet_matches[-1]\n",
    "        try:\n",
    "            tabnet_model = joblib.load(latest_tabnet)\n",
    "            meta_file = latest_tabnet.with_suffix('.json')\n",
    "            if meta_file.exists():\n",
    "                with open(meta_file) as f:\n",
    "                    tabnet_model_meta = json.load(f)\n",
    "            print(f\"[TabNet] Late-loaded saved model: {latest_tabnet.name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[TabNet] Late-load failed: {e}\")\n",
    "\n",
    "# Run TabNet optimization (wrapper handles dense conversion & y reshape)\n",
    "if tabnet_model is None or FORCE_RETRAIN:\n",
    "    print(f\"[TabNet] Starting Optuna optimization (FAST_TABNET={FAST_TABNET})\")\n",
    "    tabnet_study, tabnet_best_params = optimize_model_with_optuna(\n",
    "        model_name='TabNetRegressor',\n",
    "        estimator_builder=build_tabnet_estimator,\n",
    "        param_space_fn=tabnet_param_space,\n",
    "        X=X_train_enc,\n",
    "        y=y_train,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        cv=3,\n",
    "        n_trials=5 if FAST_TABNET else 15,\n",
    "        direction='minimize',\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    print('Best TabNetRegressor params:', tabnet_best_params)\n",
    "    tabnet_model = build_tabnet_estimator(tabnet_best_params)\n",
    "    tabnet_model.fit(X_train_enc, y_train)\n",
    "    tabnet_valid_pred = tabnet_model.predict(X_valid_enc)\n",
    "    tabnet_test_pred = tabnet_model.predict(X_test_enc)\n",
    "    save_model(tabnet_model, 'tabnet_opt', {'best_params': tabnet_best_params, 'fast_mode': FAST_TABNET})\n",
    "else:\n",
    "    # Refit even when preloaded to ensure model aligns with current transformed features\n",
    "    print(f\"[TabNet] Using loaded model; refitting on current data (FAST_TABNET={FAST_TABNET}).\")\n",
    "    reuse_params = None\n",
    "    try:\n",
    "        if 'tabnet_model_meta' in globals() and isinstance(tabnet_model_meta, dict):\n",
    "            reuse_params = tabnet_model_meta.get('best_params')\n",
    "    except Exception:\n",
    "        reuse_params = None\n",
    "    if reuse_params is None:\n",
    "        reuse_params = {}\n",
    "    reuse_params['fast'] = FAST_TABNET\n",
    "    tabnet_model = build_tabnet_estimator(reuse_params)\n",
    "    tabnet_model.fit(X_train_enc, y_train)\n",
    "    tabnet_valid_pred = tabnet_model.predict(X_valid_enc)\n",
    "    tabnet_test_pred = tabnet_model.predict(X_test_enc)\n",
    "    save_model(tabnet_model, 'tabnet_opt_refit', {'refit': True, 'best_params': reuse_params, 'fast_mode': FAST_TABNET})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2adcc8",
   "metadata": {},
   "source": [
    "# 5. Tree-based ensemble models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b7c82e",
   "metadata": {},
   "source": [
    "## XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07f9c81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[XGBoost] Preloaded model found; refitting on current data.\n",
      "Saved model -> xgboost_opt_refit_20251006T160058Z.joblib; metadata -> xgboost_opt_refit_20251006T160058Z.json\n",
      "Saved model -> xgboost_opt_refit_20251006T160058Z.joblib; metadata -> xgboost_opt_refit_20251006T160058Z.json\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter optimization and training for ensemble models\n",
    "def build_xgb_estimator(params: Dict) -> XGBRegressor:\n",
    "    base_params = {\n",
    "        'random_state': 42,\n",
    "        'device': 'cuda',\n",
    "        'verbosity': 0,\n",
    "        'tree_method': 'gpu_hist'\n",
    "    }\n",
    "    base_params.update(params)\n",
    "    return XGBRegressor(**base_params)\n",
    "\n",
    "\n",
    "def xgb_param_space(trial: optuna.trial.Trial) -> Dict:\n",
    "    return {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 200, 600),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 1e-1, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 1e-1, log=True)\n",
    "    }\n",
    "\n",
    "if xgb_model is None or FORCE_RETRAIN:\n",
    "    print(\"[XGBoost] No preloaded model (or FORCE_RETRAIN=True). Starting Optuna optimization...\")\n",
    "    xgb_study, xgb_best_params = optimize_model_with_optuna(\n",
    "        model_name='XGBoost',\n",
    "        estimator_builder=build_xgb_estimator,\n",
    "        param_space_fn=xgb_param_space,\n",
    "        X=X_train_enc,\n",
    "        y=y_train,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        cv=3,\n",
    "        n_trials=15,\n",
    "        direction='minimize',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    print('Best XGBoost params:', xgb_best_params)\n",
    "    # Fit model with optimized hyperparameters\n",
    "    xgb_model = build_xgb_estimator(xgb_best_params)\n",
    "    xgb_model.fit(X_train_enc, y_train)\n",
    "    xgb_valid_pred = xgb_model.predict(X_valid_enc)\n",
    "    xgb_test_pred = xgb_model.predict(X_test_enc)\n",
    "    save_model(xgb_model, 'xgboost_opt', {'best_params': xgb_best_params})\n",
    "else:\n",
    "    # Refit even when preloaded to ensure alignment with current data & preprocessing\n",
    "    print('[XGBoost] Preloaded model found; refitting on current data.')\n",
    "    # Try to pull previously stored best params from metadata if available\n",
    "    reuse_params = None\n",
    "    try:\n",
    "        if 'xgb_model_meta' in globals() and isinstance(xgb_model_meta, dict):\n",
    "            reuse_params = xgb_model_meta.get('best_params')\n",
    "    except Exception:\n",
    "        reuse_params = None\n",
    "    if reuse_params is None:\n",
    "        # Fall back to current model's parameters (filter to search space + core)\n",
    "        try:\n",
    "            current = xgb_model.get_params()\n",
    "            reuse_keys = {'n_estimators','max_depth','learning_rate','subsample','colsample_bytree','reg_alpha','reg_lambda'}\n",
    "            reuse_params = {k: v for k, v in current.items() if k in reuse_keys}\n",
    "        except Exception:\n",
    "            reuse_params = {}\n",
    "    # Rebuild a fresh estimator to avoid any internal state carry-over\n",
    "    xgb_model = build_xgb_estimator(reuse_params)\n",
    "    xgb_model.fit(X_train_enc, y_train)\n",
    "    xgb_valid_pred = xgb_model.predict(X_valid_enc)\n",
    "    xgb_test_pred = xgb_model.predict(X_test_enc)\n",
    "    # Save refit artifact\n",
    "    save_model(xgb_model, 'xgboost_opt_refit', {'refit': True, 'best_params': reuse_params})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a229be5e",
   "metadata": {},
   "source": [
    "# RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6950519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RandomForest] Using preloaded optimized model. Skipping training.\n"
     ]
    }
   ],
   "source": [
    "def build_rf_estimator(params: Dict) -> RandomForestRegressor:\n",
    "    base_params = {\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "    base_params.update(params)\n",
    "    return RandomForestRegressor(**base_params)\n",
    "\n",
    "\n",
    "def rf_param_space(trial: optuna.trial.Trial) -> Dict:\n",
    "    return {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 200, 800),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 25),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 5),\n",
    "        'max_features': trial.suggest_float('max_features', 0.4, 1.0)\n",
    "    }\n",
    "\n",
    "if rf_model is None or FORCE_RETRAIN:\n",
    "    print(\"[RandomForest] No preloaded model (or FORCE_RETRAIN=True). Starting Optuna optimization...\")\n",
    "    rf_study, rf_best_params = optimize_model_with_optuna(\n",
    "        model_name='RandomForest',\n",
    "        estimator_builder=build_rf_estimator,\n",
    "        param_space_fn=rf_param_space,\n",
    "        X=X_train_enc,\n",
    "        y=y_train,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        cv=3,\n",
    "        n_trials=25,\n",
    "        direction='minimize',\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    print('Best Random Forest params:', rf_best_params)\n",
    "    rf_model = build_rf_estimator(rf_best_params)\n",
    "    rf_model.fit(X_train_enc, y_train)\n",
    "    rf_valid_pred = rf_model.predict(X_valid_enc)\n",
    "    rf_test_pred = rf_model.predict(X_test_enc)\n",
    "    save_model(rf_model, 'random_forest_opt', {'best_params': rf_best_params})\n",
    "else:\n",
    "    print(\"[RandomForest] Using preloaded optimized model. Skipping training.\")\n",
    "    rf_valid_pred = rf_model.predict(X_valid_enc)\n",
    "    rf_test_pred = rf_model.predict(X_test_enc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cd472e",
   "metadata": {},
   "source": [
    "## 6. Compare Model Performance\n",
    "Evaluate predictions from each model using RMSE, MAE, and R metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4a49c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for metrics\n",
    "\n",
    "def adjusted_r2_score(r2, n, p):\n",
    "    return 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "def regression_metrics(y_true, y_pred, X=None):\n",
    "    try:\n",
    "        # Try using root_mean_squared_error if available (sklearn >= 1.4)\n",
    "        from sklearn.metrics import root_mean_squared_error\n",
    "        rmse = root_mean_squared_error(y_true, y_pred)\n",
    "    except ImportError:\n",
    "        # Fall back to mean_squared_error with squared=False for older versions\n",
    "        rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    \n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    metrics = {'RMSE': rmse, 'MAE': mae, 'R2': r2}\n",
    "    if X is not None:\n",
    "        n = X.shape[0]\n",
    "        p = X.shape[1]\n",
    "        adj_r2 = adjusted_r2_score(r2, n, p)\n",
    "        metrics['Adj_R2'] = adj_r2\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3ceb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive Model Performance Comparison & Best Model Selection (All Methods)\n",
    "import json as _json_summary\n",
    "from copy import deepcopy\n",
    "\n",
    "# Utility to (re)compute metrics if predictions exist and metrics missing\n",
    "def _ensure_metrics(prefix: str, display_name: str, Xv, Xt):\n",
    "    g = globals()\n",
    "    valid_pred_var = f'{prefix}_valid_pred'\n",
    "    test_pred_var = f'{prefix}_test_pred'\n",
    "    valid_metrics_var = f'{prefix}_metrics'  # normalized name for validation metrics\n",
    "    test_metrics_var = f'{prefix}_test_metrics'\n",
    "    # Accept older naming conventions (e.g., rf_metrics already used)\n",
    "    if valid_pred_var in g:\n",
    "        if valid_metrics_var not in g or g.get(valid_metrics_var) is None:\n",
    "            try:\n",
    "                g[valid_metrics_var] = regression_metrics(y_valid, g[valid_pred_var], Xv)\n",
    "            except Exception as e:\n",
    "                print(f'[WARN] Could not compute validation metrics for {display_name}: {e}')\n",
    "                g[valid_metrics_var] = None\n",
    "    if test_pred_var in g:\n",
    "        if test_metrics_var not in g or g.get(test_metrics_var) is None:\n",
    "            try:\n",
    "                g[test_metrics_var] = regression_metrics(y_test, g[test_pred_var], Xt)\n",
    "            except Exception as e:\n",
    "                print(f'[WARN] Could not compute test metrics for {display_name}: {e}')\n",
    "                g[test_metrics_var] = None\n",
    "    return (g.get(valid_metrics_var), g.get(test_metrics_var))\n",
    "\n",
    "# Recompute core ensemble metrics if missing (guards for partial executions)\n",
    "# This path is now superseded by _ensure_metrics but kept for clarity\n",
    "if 'xgb_metrics' not in globals() and 'xgb_valid_pred' in globals():\n",
    "    xgb_metrics = regression_metrics(y_valid, xgb_valid_pred, X_valid_enc)\n",
    "if 'rf_metrics' not in globals() and 'rf_valid_pred' in globals():\n",
    "    rf_metrics = regression_metrics(y_valid, rf_valid_pred, X_valid_enc)\n",
    "if 'xgb_test_metrics' not in globals() and 'xgb_test_pred' in globals():\n",
    "    xgb_test_metrics = regression_metrics(y_test, xgb_test_pred, X_test_enc)\n",
    "if 'rf_test_metrics' not in globals() and 'rf_test_pred' in globals():\n",
    "    rf_test_metrics = regression_metrics(y_test, rf_test_pred, X_test_enc)\n",
    "\n",
    "# Model families to probe (prefix aligns with variable naming pattern)\n",
    "MODEL_PREFIXES = [\n",
    "    ('XGBoost', 'xgb'),\n",
    "    ('RandomForest', 'rf'),\n",
    "    ('LightGBM', 'lgb'),\n",
    "    ('SVR', 'svr'),\n",
    "    ('PolynomialRegression', 'poly'),\n",
    "    ('LinearRegression', 'lr'),\n",
    "    ('TorchMLP', 'mlp'),\n",
    "    ('TabNet', 'tabnet'),\n",
    "    # Baseline variants (if both baseline and tuned exist you'll see two rows)\n",
    "    ('TorchMLP_Baseline', 'mlp_baseline'),\n",
    "    ('TabNet_Baseline', 'tabnet_baseline'),\n",
    "]\n",
    "\n",
    "candidates = []\n",
    "for display_name, prefix in MODEL_PREFIXES:\n",
    "    valid_pred_var = f'{prefix}_valid_pred'\n",
    "    test_pred_var = f'{prefix}_test_pred'\n",
    "    if valid_pred_var in globals():\n",
    "        v_metrics, t_metrics = _ensure_metrics(prefix, display_name, X_valid_enc, X_test_enc)\n",
    "        if v_metrics is not None:\n",
    "            candidates.append({'Model': display_name, 'Valid': deepcopy(v_metrics), 'Test': deepcopy(t_metrics) if t_metrics else None})\n",
    "\n",
    "# (Legacy metrics variables that don't match prefix pattern already handled above)\n",
    "if not candidates:\n",
    "    print('No model metrics available yet. Run earlier training cells first.')\n",
    "else:\n",
    "    # Build a long-form DataFrame\n",
    "    rows = []\n",
    "    for c in candidates:\n",
    "        for ds in ['Valid','Test']:\n",
    "            if c[ds] is None:\n",
    "                continue\n",
    "            row = {'Model': c['Model'], 'Dataset': ds}\n",
    "            row.update(c[ds])\n",
    "            rows.append(row)\n",
    "    all_results_df = pd.DataFrame(rows).drop_duplicates(subset=['Model','Dataset']).set_index(['Model','Dataset']).sort_index()\n",
    "\n",
    "    display(all_results_df)\n",
    "\n",
    "    # Ranking based on Validation metrics only (composite)\n",
    "    val_df = all_results_df.xs('Valid', level='Dataset').copy()\n",
    "    metric_cols = [m for m in ['RMSE','MAE','R2','Adj_R2'] if m in val_df.columns]\n",
    "    if not metric_cols:\n",
    "        print('No numeric metrics found for ranking.')\n",
    "    else:\n",
    "        ranks = {}\n",
    "        for m in metric_cols:\n",
    "            ascending = m in ['RMSE','MAE']  # lower better\n",
    "            ranks[m + '_rank'] = val_df[m].rank(ascending=ascending, method='min')\n",
    "        rank_df = pd.DataFrame(ranks)\n",
    "        val_ranked = val_df.join(rank_df)\n",
    "        rank_cols = [c for c in val_ranked.columns if c.endswith('_rank')]\n",
    "        val_ranked['avg_rank'] = val_ranked[rank_cols].mean(axis=1)\n",
    "        best_model_name = val_ranked['avg_rank'].idxmin()\n",
    "        best_model_avg_rank = val_ranked.loc[best_model_name, 'avg_rank']\n",
    "        best_model_metrics_valid = val_df.loc[best_model_name]\n",
    "        try:\n",
    "            best_test_metrics = all_results_df.loc[(best_model_name, 'Test')].to_dict()\n",
    "        except KeyError:\n",
    "            best_test_metrics = None\n",
    "        print('\\n=== Validation Ranking (lower avg_rank better) ===')\n",
    "        display(val_ranked.sort_values('avg_rank'))\n",
    "\n",
    "        print(f\"\\nOverall Best Model (Validation composite rank): {best_model_name} | avg_rank={best_model_avg_rank:.2f}\")\n",
    "        print('\\nBest Model Validation Metrics:')\n",
    "        for k,v in best_model_metrics_valid.items():\n",
    "            if not k.endswith('_rank') and k != 'avg_rank':\n",
    "                print(f'  {k}: {v:.4f}' if isinstance(v,(int,float)) else f'  {k}: {v}')\n",
    "        if best_test_metrics:\n",
    "            print('\\nBest Model Test Metrics:')\n",
    "            for k,v in best_test_metrics.items():\n",
    "                print(f'  {k}: {v:.4f}' if isinstance(v,(int,float)) else f'  {k}: {v}')\n",
    "\n",
    "        # Metric-wise winners\n",
    "        metric_winners = {}\n",
    "        for m in metric_cols:\n",
    "            ascending = m in ['RMSE','MAE']\n",
    "            winner = val_df[m].idxmin() if ascending else val_df[m].idxmax()\n",
    "            metric_winners[m] = {\n",
    "                'model': winner,\n",
    "                'value': val_df.loc[winner, m]\n",
    "            }\n",
    "        print('\\n=== Metric-wise Best (Validation) ===')\n",
    "        for m, info in metric_winners.items():\n",
    "            print(f\"  {m}: {info['model']} -> {info['value']:.4f}\")\n",
    "\n",
    "        # Persist summary JSON\n",
    "        summary_path = MODEL_DIR / 'model_comparison_summary.json'\n",
    "        summary_payload = {\n",
    "            'models_evaluated': [c['Model'] for c in candidates],\n",
    "            'validation_table': val_df.to_dict(orient='index'),\n",
    "            'ranking': val_ranked[['avg_rank']].to_dict(orient='index'),\n",
    "            'metric_winners': {m: {'model': v['model'], 'value': float(v['value'])} for m,v in metric_winners.items()},\n",
    "            'overall_best_model': {\n",
    "                'name': best_model_name,\n",
    "                'validation_metrics': {k: float(v) for k,v in best_model_metrics_valid.items() if isinstance(v,(int,float))},\n",
    "                'test_metrics': {k: float(v) if isinstance(v,(int,float)) else v for k,v in (best_test_metrics or {}).items()},\n",
    "                'avg_rank': float(best_model_avg_rank)\n",
    "            }\n",
    "        }\n",
    "        try:\n",
    "            with open(summary_path, 'w') as f:\n",
    "                _json_summary.dump(summary_payload, f, indent=2)\n",
    "            print(f\"\\nSaved model comparison summary -> {summary_path.name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not save summary JSON: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959c2f4b",
   "metadata": {},
   "source": [
    "### 6.1 Learning Curves for Ensemble Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cab7fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensitivity Analysis (Partial Dependence style) & Trade-offs Summary\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "if best_model_obj is None or 'fi_df' not in globals():\n",
    "    print('Prerequisites missing: ensure best model & feature importance computed.')\n",
    "else:\n",
    "    # Choose top N features for sensitivity sweeps\n",
    "    TOP_N_SENS = 5\n",
    "    top_sens_features = fi_df.head(TOP_N_SENS)['feature'].tolist()\n",
    "    X_valid_dense = X_valid_enc.toarray() if hasattr(X_valid_enc, 'toarray') else np.asarray(X_valid_enc)\n",
    "    base_preds = best_model_obj.predict(X_valid_dense)\n",
    "    base_rmse = mean_squared_error(y_valid, base_preds, squared=False)\n",
    "    sens_records = []\n",
    "\n",
    "    for feat in top_sens_features:\n",
    "        if feat not in feature_names:\n",
    "            continue\n",
    "        col_idx = feature_names.index(feat)\n",
    "        col_values = X_valid_dense[:, col_idx]\n",
    "        # Use quantile grid for numeric-like features. For one-hot (0/1), this will just be [0,1].\n",
    "        unique_vals = np.unique(col_values)\n",
    "        if len(unique_vals) <= 2:\n",
    "            grid = unique_vals\n",
    "        else:\n",
    "            grid = np.quantile(col_values, [0.05,0.25,0.5,0.75,0.95])\n",
    "        preds_at = []\n",
    "        for gv in grid:\n",
    "            X_mod = X_valid_dense.copy()\n",
    "            X_mod[:, col_idx] = gv\n",
    "            preds_mod = best_model_obj.predict(X_mod)\n",
    "            rmse_mod = mean_squared_error(y_valid, preds_mod, squared=False)\n",
    "            preds_at.append({'feature': feat, 'value': float(gv), 'rmse': rmse_mod, 'delta_rmse': rmse_mod - base_rmse})\n",
    "        sens_records.extend(preds_at)\n",
    "\n",
    "    sens_df = pd.DataFrame(sens_records)\n",
    "    display(sens_df.head(20))\n",
    "\n",
    "    # Plot each feature's sensitivity curve\n",
    "    n_feat = len(top_sens_features)\n",
    "    fig, axes = plt.subplots(n_feat, 1, figsize=(7, 3*n_feat), sharex=False)\n",
    "    if n_feat == 1:\n",
    "        axes = [axes]\n",
    "    for ax, feat in zip(axes, top_sens_features):\n",
    "        sub = sens_df[sens_df['feature'] == feat].sort_values('value')\n",
    "        ax.plot(sub['value'], sub['rmse'], marker='o')\n",
    "        ax.axhline(base_rmse, color='gray', linestyle='--', label='Base RMSE')\n",
    "        ax.set_title(f'Sensitivity: {feat}')\n",
    "        ax.set_xlabel('Value')\n",
    "        ax.set_ylabel('RMSE')\n",
    "        ax.legend()\n",
    "        ax.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Trade-offs summary: quantify importance vs. sensitivity (range of RMSE)\n",
    "    trade_rows = []\n",
    "    for feat in top_sens_features:\n",
    "        sub = sens_df[sens_df['feature'] == feat]\n",
    "        if sub.empty:\n",
    "            continue\n",
    "        rmse_range = sub['rmse'].max() - sub['rmse'].min()\n",
    "        # Importance lookup\n",
    "        imp = fi_df.loc[fi_df['feature'] == feat, 'importance']\n",
    "        imp_val = float(imp.iloc[0]) if not imp.empty else np.nan\n",
    "        trade_rows.append({'feature': feat, 'importance': imp_val, 'rmse_range': rmse_range, 'sensitivity_score': rmse_range / (imp_val + 1e-9)})\n",
    "    trade_df = pd.DataFrame(trade_rows).sort_values('sensitivity_score', ascending=False)\n",
    "    print('\\nTrade-offs (higher sensitivity_score => large RMSE movement per unit importance):')\n",
    "    display(trade_df)\n",
    "\n",
    "    # Persist analysis artifacts\n",
    "    analysis_payload = {\n",
    "        'feature_importances': fi_df.to_dict(orient='records') if 'fi_df' in globals() else None,\n",
    "        'ablation': ablation_df.to_dict(orient='records') if 'ablation_df' in globals() else None,\n",
    "        'sensitivity': sens_df.to_dict(orient='records'),\n",
    "        'tradeoffs': trade_df.to_dict(orient='records'),\n",
    "        'best_model': best_model_name_runtime,\n",
    "        'base_validation_rmse': float(base_rmse)\n",
    "    }\n",
    "    analysis_path = MODEL_DIR / 'best_model_explainability.json'\n",
    "    try:\n",
    "        with open(analysis_path, 'w') as f:\n",
    "            json.dump(analysis_payload, f, indent=2)\n",
    "        print(f'Saved explainability analysis -> {analysis_path.name}')\n",
    "    except Exception as e:\n",
    "        print('Failed to save explainability JSON:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f036aa02",
   "metadata": {},
   "source": [
    "## 6.2 Best Model Deep Dive: Feature Importance, Ablation, Sensitivity & Tradeoffs\n",
    "This section automatically targets the currently best performing model (based on composite validation rank from the previous cell) and provides:\n",
    "1. Unified feature name extraction from the preprocessing pipeline.\n",
    "2. Multiple feature importance strategies (native, permutation).\n",
    "3. Ablation study: progressive removal (or neutralization) of top features to measure performance degradation.\n",
    "4. Sensitivity analysis: perturbation / partial dependence style sweeps for top features.\n",
    "5. Tradeoff discussion metrics (complexity vs. performance deltas).\n",
    "Run the cells below after the comparison cell has executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1937eb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ablation Analysis: neutralize/remove top-K features and measure RMSE delta\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "if best_model_obj is None or 'fi_df' not in globals():\n",
    "    print('Prerequisites missing: ensure best model & feature importance computed.')\n",
    "else:\n",
    "    base_preds = best_model_obj.predict(X_valid_enc)\n",
    "    try:\n",
    "        base_rmse = mean_squared_error(y_valid, base_preds, squared=False)\n",
    "    except Exception:\n",
    "        base_rmse = np.sqrt(mean_squared_error(y_valid, base_preds))\n",
    "    print(f'Base validation RMSE: {base_rmse:.4f}')\n",
    "\n",
    "    top_features = fi_df.head(30)['feature'].tolist()  # consider top 30 for ablation scope\n",
    "    ablation_results = []\n",
    "    # Create a mapping feature_name -> column index for efficient masking\n",
    "    feat_index_map = {f: i for i, f in enumerate(feature_names)}\n",
    "\n",
    "    X_valid_dense = X_valid_enc.toarray() if hasattr(X_valid_enc, 'toarray') else np.asarray(X_valid_enc)\n",
    "    for k in [1,2,3,5,10,15,20,25,30]:\n",
    "        subset = top_features[:k]\n",
    "        cols = [feat_index_map[f] for f in subset if f in feat_index_map]\n",
    "        if not cols:\n",
    "            continue\n",
    "        X_mod = X_valid_dense.copy()\n",
    "        # Neutralization strategy: set to column mean (could also zero)\n",
    "        for c in cols:\n",
    "            col_mean = X_mod[:, c].mean()\n",
    "            X_mod[:, c] = col_mean\n",
    "        preds_mod = best_model_obj.predict(X_mod)\n",
    "        rmse_mod = mean_squared_error(y_valid, preds_mod, squared=False)\n",
    "        ablation_results.append({'k_removed': k, 'rmse': rmse_mod, 'delta_rmse': rmse_mod - base_rmse})\n",
    "    ablation_df = pd.DataFrame(ablation_results)\n",
    "    display(ablation_df)\n",
    "\n",
    "    plt.figure(figsize=(7,4))\n",
    "    plt.plot(ablation_df['k_removed'], ablation_df['delta_rmse'], marker='o')\n",
    "    plt.axhline(0, color='gray', linestyle='--')\n",
    "    plt.xlabel('Number of Top Features Neutralized')\n",
    "    plt.ylabel('RMSE Delta vs Base')\n",
    "    plt.title(f'Ablation Impact - {best_model_name_runtime}')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423014d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance (native if available, else permutation)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "if best_model_obj is None:\n",
    "    print('Best model object not available; run previous cells.')\n",
    "else:\n",
    "    # Try native importances\n",
    "    importances = None\n",
    "    importance_type = None\n",
    "    try:\n",
    "        if hasattr(best_model_obj, 'feature_importances_'):\n",
    "            importances = getattr(best_model_obj, 'feature_importances_')\n",
    "            importance_type = 'feature_importances_'\n",
    "        elif hasattr(best_model_obj, 'coef_'):\n",
    "            coef = getattr(best_model_obj, 'coef_')\n",
    "            # Flatten if necessary\n",
    "            importances = np.abs(coef.ravel())\n",
    "            importance_type = 'coef_'\n",
    "    except Exception as e:\n",
    "        print('[Importance] Native extraction failed:', e)\n",
    "\n",
    "    if importances is None or len(importances) != len(feature_names):\n",
    "        print('[Importance] Falling back to permutation importance (n_repeats=10).')\n",
    "        try:\n",
    "            perm = permutation_importance(best_model_obj, X_valid_enc, y_valid, n_repeats=10, scoring='neg_root_mean_squared_error', n_jobs=-1, random_state=42)\n",
    "            importances = np.maximum(0, perm.importances_mean)\n",
    "            importance_type = 'permutation_neg_rmse'\n",
    "        except Exception as e:\n",
    "            print('[Importance] Permutation importance failed:', e)\n",
    "            importances = None\n",
    "\n",
    "    if importances is not None:\n",
    "        fi_df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "        fi_df = fi_df.sort_values('importance', ascending=False).reset_index(drop=True)\n",
    "        display(fi_df.head(25))\n",
    "        # Plot\n",
    "        top_plot = fi_df.head(25).iloc[::-1]\n",
    "        plt.figure(figsize=(8, max(4, 0.3*len(top_plot))))\n",
    "        plt.barh(top_plot['feature'], top_plot['importance'], color='steelblue')\n",
    "        plt.title(f'Top Feature Importances ({importance_type}) - {best_model_name_runtime}')\n",
    "        plt.xlabel('Importance')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print('Could not compute feature importance.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f735c0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select best model object + extract feature names\n",
    "from sklearn.inspection import permutation_importance\n",
    "best_model_name_runtime = None\n",
    "best_model_obj = None\n",
    "\n",
    "# If previous cell stored summary JSON, load it to get best model name\n",
    "summary_path = MODEL_DIR / 'model_comparison_summary.json'\n",
    "if summary_path.exists():\n",
    "    try:\n",
    "        with open(summary_path) as f:\n",
    "            _summary_json = json.load(f)\n",
    "        best_model_name_runtime = _summary_json.get('overall_best_model', {}).get('name')\n",
    "        print(f\"[BestModel] Loaded best model from summary JSON: {best_model_name_runtime}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[BestModel] Could not read summary JSON: {e}\")\n",
    "else:\n",
    "    print('[BestModel] Summary JSON not found. Run comparison cell first.')\n",
    "\n",
    "# Map display name to the underlying variable (heuristic)\n",
    "_MODEL_VAR_MAP = {\n",
    "    'XGBoost': 'xgb_model',\n",
    "    'RandomForest': 'rf_model',\n",
    "    'LightGBM': 'lgb_model',\n",
    "    'CatBoost': 'cat_model',\n",
    "    'SVR': 'svr_model',\n",
    "    'PolynomialRegression': 'poly_model',\n",
    "    'LinearRegression': 'lr_model',\n",
    "    'TorchMLP': 'mlp_model',\n",
    "    'TabNet': 'tabnet_model',\n",
    "}\n",
    "\n",
    "if best_model_name_runtime and best_model_name_runtime in _MODEL_VAR_MAP:\n",
    "    var_name = _MODEL_VAR_MAP[best_model_name_runtime]\n",
    "    best_model_obj = globals().get(var_name)\n",
    "    if best_model_obj is None:\n",
    "        print(f\"[BestModel] Variable '{var_name}' not found or is None; ensure model cell was executed.\")\n",
    "else:\n",
    "    print('[BestModel] Could not determine model variable mapping.')\n",
    "\n",
    "# Extract feature names after preprocessing\n",
    "def get_feature_names(preprocessor):\n",
    "    feat_names = []\n",
    "    try:\n",
    "        # Numeric\n",
    "        for name, trans, cols in preprocessor.transformers_:\n",
    "            if name == 'remainder':\n",
    "                continue\n",
    "            if name == 'num':\n",
    "                feat_names.extend(cols)\n",
    "            elif name == 'cat':\n",
    "                # OneHotEncoder inside pipeline\n",
    "                try:\n",
    "                    ohe = trans.named_steps['onehot'] if hasattr(trans, 'named_steps') else trans\n",
    "                    cats = ohe.get_feature_names_out(cols)\n",
    "                    feat_names.extend(cats)\n",
    "                except Exception as e:\n",
    "                    print('[FeatureNames] OHE extraction failed:', e)\n",
    "    except Exception as e:\n",
    "        print('[FeatureNames] Fallback feature name generation:', e)\n",
    "        # Fallback to generic idx names\n",
    "        feat_names = [f'f{i}' for i in range(X_train_enc.shape[1])]\n",
    "    if len(feat_names) != X_train_enc.shape[1]:\n",
    "        # Align length via fallback if mismatch\n",
    "        print('[FeatureNames] Length mismatch; falling back to positional feature names.')\n",
    "        feat_names = [f'f{i}' for i in range(X_train_enc.shape[1])]\n",
    "    return feat_names\n",
    "\n",
    "feature_names = get_feature_names(preprocessor)\n",
    "print(f\"Extracted {len(feature_names)} feature names.\")\n",
    "if best_model_name_runtime:\n",
    "    print(f\"Proceeding with best model: {best_model_name_runtime}\")\n",
    "else:\n",
    "    print('Best model not established yet. Subsequent cells may fail.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124766b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning curves for ensemble models\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.base import clone\n",
    "\n",
    "def plot_learning_curve(estimator, X, y, ax, title, cv=5, scoring='neg_root_mean_squared_error'):\n",
    "    train_sizes, train_scores, valid_scores = learning_curve(\n",
    "        estimator,\n",
    "        X,\n",
    "        y,\n",
    "        cv=cv,\n",
    "        scoring=scoring,\n",
    "        n_jobs=-1,\n",
    "        train_sizes=np.linspace(0.1, 1.0, 6),\n",
    "        shuffle=True,\n",
    "        random_state=42\n",
    "    )\n",
    "    train_rmse = -train_scores.mean(axis=1)\n",
    "    valid_rmse = -valid_scores.mean(axis=1)\n",
    "\n",
    "    ax.plot(train_sizes, train_rmse, label='Train RMSE', marker='o')\n",
    "    ax.fill_between(train_sizes, train_rmse - train_scores.std(axis=1), train_rmse + train_scores.std(axis=1), alpha=0.2)\n",
    "    ax.plot(train_sizes, valid_rmse, label='Validation RMSE', marker='s')\n",
    "    ax.fill_between(train_sizes, valid_rmse - valid_scores.std(axis=1), valid_rmse + valid_scores.std(axis=1), alpha=0.2)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Training Examples')\n",
    "    ax.set_ylabel('RMSE')\n",
    "    ax.legend()\n",
    "    ax.grid(True, linestyle='--', alpha=0.4)\n",
    "\n",
    "xgb_curve_model = clone(xgb_model)\n",
    "rf_curve_model = clone(rf_model)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5), sharey=True)\n",
    "plot_learning_curve(xgb_curve_model, X_train_enc, y_train, axes[0], 'XGBoost Learning Curve')\n",
    "plot_learning_curve(rf_curve_model, X_train_enc, y_train, axes[1], 'Random Forest Learning Curve')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9785e3e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "milestone2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
